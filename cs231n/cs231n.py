# coding=utf-8
# -*- coding:cp936 -*-
""""""

''' 损失函数 Loss function '''

# 损失函数(Loss Function)(有时也叫代价函数Cost Function或目标函数Objective)来衡量我们对结果的不满意程度
# 直观地讲, 当评分函数输出结果与真实结果之间差异越大, 损失函数输出越大, 反之越小
# 损失函数的具体形式多种多样

''' 正则化 Regularization '''

# 假设输入向量x = [1, 1, 1, 1], 两个权重向量w1 = [1, 0, 0, 0], w2 = [0.25, 0.25, 0.25, 0.25]
# w1.T * x = w2.T * x = 1, 两个权重向量都得到同样的内积,
# 从直观上来看, w2权重值更小且更分散, L2惩罚倾向于更小更分散的权重向量, 鼓励分类器最终将所有维度上的特征都用起来
# 而不是强烈依赖其中少数几个维度, 这一效果将会提升分类器的泛化能力, 并避免过拟合

# 偏差没有这样的效果, 因为它们并不控制输入维度上的影响强度
# 因此通常只对权重W正则化, 而不正则化偏差b, 在实际操作中, 可发现这一操作的影响可忽略不计

# 引入正则化惩罚还带来很多良好的性质, 比如引入了L2惩罚后, SVM们就有了最大边界(max margin)这一良好性质

# 正则化惩罚(regularization penalty) R(W)部分, 最常用的正则化惩罚是L2范式, L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重:
# R(W) = sum(sum(Wkl**2, l), k)
# 上面的表达式中, 将W中所有元素平方后求和, 注意正则化函数不是数据的函数, 仅基于权重, 包含正则化惩罚后, 就能够给出完整的多类SVM损失函数了
# L = data loss + regularization loss
# data loss = (1/N) * sum(Li, i)    regularization loss = λ * R(W)
# L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)_j - f(x_i; W)_{y_i} + \Delta) \right] +
# \lambda \sum_k\sum_l W_{k,l}^2
# N是训练集的数据量, 现在正则化惩罚添加到了损失函数里面, 并用超参数lambda来计算其权重, 该超参数无法简单确定, 需要通过交叉验证来获取

# 代码: 下面是一个无正则化部分的损失函数的Python实现, 有非向量化和半向量化两个形式:

''' Softmax分类器 '''

# SVM将输出f(xi, W)作为每个分类的评分(因为无定标, 所以难以直接解释)
# 与SVM不同, Softmax的输出(归一化的分类概率)更加直观, 并且从概率上可以解释

# 在Softmax分类器中, 函数映射f(xi, W) = W * xi 保持不变, 但将这些评分值视为每个分类的未归一化的对数概率
# 并且将折叶损失(hinge loss)替换为交叉熵损失(cross-entropy loss)
# Li = -log( e^fyi / sum j e^fj )

# 使用fj来表示分类评分向量f中的第j个元素, 和之前一样, 整个数据集的损失值是数据集中所有样本数据的损失值Li的均值与正则化损失R(W)之和
# fj(z) 被称作softmax 函数: 其输入值是一个向量, 向量中元素为任意实数的评分值(z中的),
# 函数对其进行压缩, 输出一个向量, 其中每个元素值在0到1之间, 且所有元素之和为1
# 交叉熵损失函数'想要'预测分布的所有概率密度都在正确分类上

# 编程实现softmax函数计算的时候, 因为存在指数函数, 所以数值可能非常大, 除以大数值可能导致数值计算的不稳定
# 就是应该将向量f中的数值进行平移，使得最大值为0

# f = np.array([123, 456, 789])  # 例子中有3个分类，每个评分的数值都很大
# p = np.exp(f) / np.sum(np.exp(f))  # 不妙：数值问题，可能导致数值爆炸
# 那么将f中的值平移到最大值为0：
# f -= np.max(f)  # f becomes [-666, -333, 0]
# p = np.exp(f) / np.sum(np.exp(f))  # 现在OK了，将给出正确结果

# 精确地说, SVM分类器使用的是折叶损失(hinge loss), 有时候又被称为最大边界损失(max-margin loss)
# Softmax分类器使用的是交叉熵损失(cross-entropy loss) Softmax分类器的命名是从softmax函数那里得来的
# softmax函数将原始分类评分变成正的归一化数值, 所有数值和为1, 这样处理后交叉熵损失才能应用
# 注意从技术上说'softmax损失(softmax loss)'是没有意义的, 因为softmax只是一个压缩数值的函数, 但是在这个说法常常被用来做简称

# Softmax分类器为每个分类提供了'可能性': 举个例子, 针对给出的图像, SVM分类器可能给你的是一个[12.5, 0.6, -23.0]对应分类“猫”，“狗”，“船”
# 而softmax分类器可以计算出这三个标签的'可能性'是[0.9, 0.09, 0.01], 这就让你能看出对于不同分类准确性的把握
# 为什么我们要在'可能性'上面打引号呢? 这是因为可能性分布的集中或离散程度是由正则化参数λ直接决定的, λ是你能直接控制的一个输入参数
# 举个例子, 假设3个分类的原始分数是[1, -2, 0]，那么softmax函数就会计算: [2.71, 0.14, 1] -> [0.7, 0.04, 0.26]
# 现在, 如果正则化参数λ更大, 那么权重W就会被惩罚的更多, 然后他的权重数值就会更小, 这样算出来的分数也会更小
# 假设小了一半吧[0.5, -1, 0], 那么softmax函数的计算就是: [1.65, 0.73, 1] -> [0.55, 0.12, 0.33]

# 现在看起来, 概率的分布就更加分散了, 还有, 随着正则化参数λ不断增强, 权重数值会越来越小, 最后输出的概率会接近于均匀分布
# 这就是说, softmax分类器算出来的概率最好是看成一种对于分类正确性的自信
# 和SVM一样, 数字间相互比较得出的大小顺序是可以解释的，但其绝对值则难以直观解释


''' 最优化 Optimization '''

# 最优化是寻找能使得损失函数值最小化的参数W的过程

# 一旦理解了这三个部分(评分函数, 损失函数, 最优化)是如何相互运作的, 我们将会回到第一个部分(基于参数的函数映射)
# 然后将其拓展为一个远比线性函数复杂的函数: 首先是神经网络, 然后是卷积神经网络, 而损失函数和最优化过程这两个部分将会保持相对稳定

# 策略1:一个差劲的初始方案：随机搜索
# 第一个想到的(差劲)方法, 就是可以随机尝试很多不同的权重, 然后看其中哪个最好
# 假设X_train的每一列都是一个数据样本（比如3073 x 50000）
# 假设Y_train是数据样本的类别标签（比如一个长50000的一维数组）
# 假设函数L对损失函数进行评价


# 核心思路:迭代优化
# 虽然找到最优的权重W非常困难, 甚至是不可能的(尤其当W中存的是整个神经网络的权重的时候),
# 但如果问题转化为: 对一个权重矩阵集W取优, 使其损失值稍微减少, 那么问题的难度就大大降低了
# 换句话说, 我们的方法从一个随机的W开始, 然后对其迭代取优, 每次都让它的损失值变得更小一点
# 蒙眼徒步者的比喻: 一个助于理解的比喻是把你自己想象成一个蒙着眼睛的徒步者, 正走在山地地形上, 目标是要慢慢走到山底
# 在CIFAR-10的例子中, 这山是30730维的(因为W是10x3073), 我们在山上踩的每一点都对应一个的损失值, 该损失值可以看做该点的海拔高度

# 策略2: 随机本地搜
# 第一个策略可以看做是每走一步都尝试几个随机方向, 如果某个方向是向山下的, 就向该方向走一步
# 这次我们从一个随机W开始, 然后生成一个随机的扰动delta W, 只有当 W + delta W 的损失值变低, 我们才会更新

# W = np.random.randn(10, 3073) * 0.001  # 生成随机初始W
# bestloss = float("inf")
# for i in range(1000):
#     step_size = 0.0001
#     Wtry = W + np.random.randn(10, 3073) * step_size
#     loss = L(Xtr_cols, Ytr, Wtry)
#     if loss < bestloss:
#         W = Wtry
#         bestloss = loss
#     print('iter %d loss is %f' % (i, bestloss))

# 这个比策略一好, 但是依然过于浪费计算资源

# 策略3: 跟随梯度
# 前两个策略中, 我们是尝试在权重空间中找到一个方向, 沿着该方向能降低损失函数的损失值
# 其实不需要随机寻找方向, 因为可以直接计算出最好的方向, 这就是从数学上计算出最陡峭的方向, 这个方向就是损失函数的梯度(gradient)
# 在蒙眼徒步者的比喻中, 这个方法就好比是感受我们脚下山体的倾斜程度, 然后向着最陡峭的下降方向下山

# 在一维函数中, 斜率(导数)是函数在某一点的瞬时变化率, 梯度是函数斜率的一般化表达, 它不是一个值, 而是一个向量
# 在输入空间中, 梯度是各个维度的斜率(偏导数)组成的向量

''' 梯度计算 '''

# 计算梯度有两种方法: 一个是缓慢的近似方法(数值梯度法), 但实现相对简单
# 另一个方法(分析梯度法)计算迅速, 结果精确, 但是实现时容易出错, 且需要使用微分

''' 利用有限差值计算梯度 '''

# df(x)/dx = lim h->0  ( f(x+h) - f(x) / h )


# 代码对所有维度进行迭代, 在每个维度上产生一个很小的变化h, 通过观察函数值变化, 计算函数在该维度上的偏导数
# 最后, 所有的梯度存储在变量grad中

# 实践考量: 注意在数学公式中, h的取值是趋近于0的, 然而在实际中, 用一个很小的数值(比如例子中的1e-5)就足够了
# 在不产生数值计算出错的理想前提下, 你会使用尽可能小的h, 还有, 实际中用中心差值公式(centered difference formula)效果较好

# 要使用上面的代码我们需要一个只有一个参数的函数 (在这里参数就是权重)所以也包含了Xtr和Ytr


# 在梯度负方向上更新: 在上面的代码中, 为了计算W_new, 要注意我们是向着梯度df的负方向去更新, 这是因为我们希望损失函数值是降低而不是升高。

# 步长的影响: 梯度指明了函数在哪个方向是变化率最大的, 但是没有指明在这个方向上应该走多远
# 在后续的课程中可以看到, 选择步长(也叫作学习率)将会是神经网络训练中最重要(也是最头痛)的超参数设定之一
# 还是用蒙眼徒步者下山的比喻, 这就好比我们可以感觉到脚朝向的不同方向上, 地形的倾斜程度不同, 但是该跨出多长的步长呢?
# 不确定, 如果谨慎地小步走, 情况可能比较稳定但是进展较慢(这就是步长较小的情况), 相反, 如果想尽快下山, 那就大步走吧
# 但结果也不一定尽如人意, 在上面的代码中就能看见反例, 在某些点如果步长过大, 反而可能越过最低点导致更高的损失值

# 效率问题: 计算数值梯度的复杂性和参数的量线性相关, 在本例中有30730个参数, 所以损失函数每走一步就需要计算30731次损失函数的梯度
# 现代神经网络很容易就有上千万的参数, 因此这个问题只会越发严峻, 显然这个策略不适合大规模数据, 我们需要更好的策略

''' 微分分析计算梯度 '''

# 使用有限差值近似计算梯度比较简单, 但缺点在于终究只是近似(因为我们对于h值是选取了一个很小的数值, 但真正的梯度定义中h趋向0的极限)
# 且耗费计算资源太多, 第二个梯度计算方法是利用微分来分析, 能得到计算梯度的公式(不是近似), 用公式计算梯度速度很快
# 唯一不好的就是实现的时候容易出错, 为了解决这个问题, 在实际操作时常常将分析梯度法的结果和数值梯度法的结果作比较
# 以此来检查其实现的正确性, 这个步骤叫做梯度检查

# \nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta > 0) x_i

# 梯度下降
# 普通的梯度下降

# while True:
#   weights_grad = evaluate_gradient(loss_fun, data, weights)
#   weights += - step_size * weights_grad # 进行梯度更新

# 这个简单的循环在所有的神经网络核心库中都有, 虽然也有其他实现最优化的方法(比如LBFGS)
# 但是到目前为止, 梯度下降是对神经网络的损失函数最优化中最常用的方法
# 课程中, 我们会在它的循环细节增加一些新的东西(比如更新的具体公式), 但是核心思想不变, 那就是我们一直跟着梯度走, 直到结果不再变化

# 小批量数据梯度下降(Mini-batch gradient descent)
# 在大规模的应用中(比如ILSVRC挑战赛), 训练数据可以达到百万级量级, 如果像这样计算整个训练集, 来获得仅仅一个参数的更新就太浪费了
# 一个常用的方法是计算训练集中的小批量(batches)数据, 例如, 在目前最高水平的卷积神经网络中, 一个典型的小批量包含256个例子
# 而整个训练集是多少呢? 一百二十万个, 这个小批量数据就用来实现一个参数更新:

# 普通的小批量数据梯度下降

# while True:
#   data_batch = sample_training_data(data, 256) # 256个数据
#   weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
#   weights += - step_size * weights_grad # 参数更新

# 这个方法之所以效果不错, 是因为训练集中的数据都是相关的, 要理解这一点, 可以想象一个极端情况:
# 在ILSVRC中的120万个图像是1000张不同图片的复制(每个类别1张图片，每张图片有1200张复制)
# 那么显然计算这1200张复制图像的梯度就应该是一样的, 对比120万张图片的数据损失的均值与只计算1000张的子集的数据损失均值时, 结果应该是一样的
# 实际情况中, 数据集肯定不会包含重复图像, 那么小批量数据的梯度就是对整个数据集梯度的一个近似
# 因此, 在实践中通过计算小批量数据的梯度可以实现更快速地收敛, 并以此来进行更频繁的参数更新

# 小批量数据策略有个极端情况, 那就是每个批量中只有1个数据样本, 这种策略被称为随机梯度下降(Stochastic Gradient Descent 简称SGD)
# 有时候也被称为在线梯度下降, 这种策略在实际情况中相对少见, 因为向量化操作的代码一次计算100个数据 比100次计算1个数据要高效很多
# 即使SGD在技术上是指每次使用1个数据来计算梯度, 你还是会听到人们使用SGD来指代小批量数据梯度下降(或者用MGD来指代小批量数据梯度下降
# 而BGD来指代则相对少见), 小批量数据的大小是一个超参数, 但是一般并不需要通过交叉验证来调参
# 它一般由存储器的限制来决定的, 或者干脆设置为同样大小, 比如32, 64, 128等
# 之所以使用2的指数, 是因为在实际中许多向量化操作实现的时候, 如果输入数据量是2的倍数, 那么运算更快

# 信息流的总结
# 数据集中的{x,y}是给定的, 权重从一个随机数字开始, 且可以改变,
# 在前向传播时, 评分函数计算出类别的分类评分并存储在向量f中
# 损失函数包含两个部分: 数据损失和正则化损失
# 其中, 数据损失计算的是分类评分f和实际标签y之间的差异
# 正则化损失只是一个关于权重的函数
# 在梯度下降过程中, 我们计算权重的梯度, 然后使用它们来实现参数的更新

# 理解并能计算损失函数关于权重的梯度, 是设计, 训练和理解神经网络的核心能力
# 下节中, 将介绍如何使用链式法则来高效地计算梯度, 也就是通常所说的反向传播(backpropagation)机制
# 该机制能够对几乎所有类型的神经网络的损失函数进行高效的最优化

''' 反向传播 '''

# 利用链式法则递归计算梯度
# 核心问题: 给定函数 f(x), 其中 x 是输入数据的向量, 需要计算函数 f 关于 x 的梯度, 也就是 ∇f(x)

# 在神经网络中 f 对应的是损失函数 (L), 输入 x 包含训练数据(固定)和神经网络的权重(可变)
# 举个例子, 损失函数可以是SVM的损失函数, 输入则包含了训练数据{xi, yi}, i = 1,...,N, 权重和偏差
# 注意训练集是给定的(在机器学习中通常都是这样), 而权重是可以控制的变量
# 因此, 即使能用反向传播计算输入数据xi上的梯度, 但在实践中为了进行参数更新, 通常也只计算参数(比如W, b)的梯度
# 然而xi的梯度有时仍然是有用的: 比如将神经网络所做的事情可视化便于直观理解的时候, 就能用上


''' 简单表达式和理解梯度 '''

# 先考虑一个简单的二元乘法函数f(x,y) = x * y, 对两个输入变量分别求偏导数还是很简单的:
# df/dx = y, df/dy = x
# 导数的意义: 函数变量在某个点周围的极小区域内变化, 导数就是变量变化导致的函数在该方向上的变化率
# df(x)/dx = lim h->0  (f(x+h) - f(x)) / h

# 对于上述公式, 可以认为 h 值非常小, 函数可以被一条直线近似(函数变化 = 导数 * 变量变化), 而导数就是这条直线的斜率
# 导数指明了整个表达式对于该变量的值的敏感程度(函数对于该变量的变化率)
# 比如, 若 x = 4, y = -3, 则 f(x, y) = -12, x 的导数 df/dx = -3
# 这就说明, 如果将变量 x 的值变大一点, 整个表达式的值就会变小(原因在于负号), 而且变小的量是 x 变大的量的三倍
# 通过重新排列公式可以看到这一点 f(x+h) = f(x) + h * df/dx
# 同样, 因为 df/dy = 4, 可以知道如果将 y 的值增加 h, 那么函数的输出也将增加(原因在于正号), 且增加量是 4h

# 函数关于每个变量的导数指明了整个表达式对于该变量的敏感程度

# 梯度 ∇f 是偏导数的向量, 所以有 ∇f(x) = [df/dx, df/dy] = [y, x]
# 即使是梯度实际上是一个向量, 仍然通常使用类似'x上的梯度'的术语, 而不是使用如'x的偏导数'的正确说法, 原因是因为前者说起来简单

# 加法求导:
# f(x, y) = x + y, -> df/dx = 1, df/dy = 1
# 这就是说, 无论其值如何, x, y的导数均为1
# 因为无论增加x, y中任一个的值, 函数f的值都会增加, 并且增加的变化率独立于x, y的具体值(情况和乘法操作不同)

# max求导:
# f(x, y) = max(x, y)  ->  df/dx = 1 (x >y)  df/dx = 1 (y > x)
# 上式是说, 如果该变量比另一个变量大, 那么梯度是1, 反之为0
# 例如, 若 x = 4, y = 2, 那么max是4, 所以函数对于y就不敏感
# 也就是说, 在y上增加 h, 函数还是输出为4, 所以梯度是0: 因为对于函数输出是没有效果的
# 当然, 如果给增加一个很大的量, 比如大于2, 那么函数的值就变化了, 但是导数并没有指明输入量有巨大变化情况对于函数的效果
# 他们只适用于输入量变化极小时的情况, 因为定义已经指明: lim h -> 0

''' 使用链式法则计算复合表达式 '''

# 反向传播的直观理解
# 在整个计算线路图中, 每个门单元都会得到一些输入并立即计算两个东西 1. 这个门的输出值 2. 其输出值关于输入值的局部梯度
# 门单元完成这两件事是完全独立的, 它不需要知道计算线路中的其他细节
# 然而, 一旦前向传播完毕, 在反向传播的过程中, 门单元门将最终获得整个网络的最终输出值在自己的输出值上的梯度
# 链式法则指出, 门单元应该将回传的梯度乘以它对其的输入的局部梯度, 从而得到整个网络的输出对该门单元的每个输入值的梯度

# 反向传播可以看做是门单元之间在通过梯度信号相互通信, 只要让它们的输入沿着梯度方向变化
# 无论它们自己的输出值在何种程度上升或降低都是为了让整个网络的输出值更高

# 任何可微分的函数都可以看做门(为计算梯度所以激活函数要可微分)
# 可以将多个门组合成一个门, 也可以根据需要将一个函数分拆成多个门

# 加法操作: 将(前一)梯度相等地分发给它的输入
# 取最大操作: 将(前一)梯度路由给更大的输入
# 乘法操作: 拿取输入激活数据, 对它们进行交换, 然后乘以(前一)梯度

# 在线性分类器中, 权重和输入是进行点积, 这说明输入数据的大小对于权重梯度的大小有影响
# 例如, 在计算过程中对所有输入数据样本乘以1000, 那么权重的梯度将会增大1000倍, 这样就必须降低学习率来弥补
# 这就是为什么数据预处理关系重大, 它即使只是有微小变化，也会产生巨大影响


# 对前向传播变量进行缓存: 在计算反向传播时, 前向传播过程中得到的一些中间变量非常有用
# 在实际操作中, 最好代码实现对于这些中间变量的缓存, 这样在反向传播的时候也能用上它们
# 如果这样做过于困难, 也可以(但是浪费计算资源)重新计算它们

# 在不同分支的梯度要相加: 如果变量 x, y 在前向传播的表达式中出现多次, 那么进行反向传播的时候就要非常小心
# 使用+=而不是=来累计这些变量的梯度(不然就会造成覆写) 这是遵循了在微积分中的多元链式法则
# 该法则指出如果变量在线路中分支走向不同的部分, 那么梯度在回传的时候, 就应该进行累加


''' 神经网络 '''
# 在线性分类中, 在给出图像的情况下, 是使用 s = W * x 来计算不同视觉类别的评分, 其中是一个矩阵, 是一个输入列向量, 它包含了图像的全部像素数据
# 在使用数据库CIFAR-10的案例中, x 是一个[3072x1]的列向量, W 是一个[10x3072]的矩阵, 所以输出的评分是一个包含10个分类评分的向量

# 神经网络算法则不同, 它的计算公式是 s = W2 * max(0, W1 * x)
# 其中的含义是这样的: 举个例子来说, 它可以是一个[100x3072]的矩阵, 其作用是将图像转化为一个100维的过渡向量
# 函数max(0, _)是非线性的, 它会作用到每个元素, 这个非线性函数有多种选择
# 但这个形式是一个最常用的选择, 它就是简单地设置阈值, 将所有小于0的值变成0
# 最终, 矩阵 W2 的尺寸是[10x100], 因此将得到10个数字, 这10个数字可以解释为是分类的评分
# 非线性函数在计算上是至关重要的, 如果略去这一步, 那么两个矩阵将会合二为一, 对于分类的评分计算将重新变成关于输入的线性函数
# 非线性函数就是改变的关键点
# 参数 W1, W2 将通过随机梯度下降来学习到, 他们的梯度在反向传播过程中, 通过链式法则来求导计算得出

# 一个三层的神经网络可以类比地看做 s = W3 * max(0, W2 * max(0, W1 * x)), 其中W1, W2, W3 是需要进行学习的参数
# 中间隐层的尺寸是网络的超参数, 后续将学习如何设置它们

''' 激活函数 '''
# ReLU
# 在近些年ReLU变得非常流行
# 它的函数公式是。换句话说，这个激活函数就是一个关于0的阈值（如上图左侧）。使用ReLU有以下一些优缺点：

# 优点：相较于sigmoid和tanh函数，ReLU对于随机梯度下降的收敛有巨大的加速作用（ Krizhevsky 等的论文指出有6倍之多）。
# 据称这是由它的线性，非饱和的公式导致的。
# 优点：sigmoid和tanh神经元含有指数运算等耗费计算资源的操作，而ReLU可以简单地通过对一个矩阵进行阈值计算得到。
# 缺点：在训练的时候，ReLU单元比较脆弱并且可能“死掉”。举例来说，当一个很大的梯度流过ReLU的神经元的时候，
# 可能会导致梯度更新到一种特别的状态，在这种状态下神经元将无法被其他任何数据点再次激活。
# 如果这种情况发生，那么从此所以流过这个神经元的梯度将都变成0。也就是说，这个ReLU单元在训练中将不可逆转的死亡，因为这导致了数据多样化的丢失。
# 例如，如果学习率设置得太高，可能会发现网络中40%的神经元都会死掉（在整个训练集中这些神经元都不会被激活）。
# 通过合理设置学习率，这种情况的发生概率会降低。

# Leaky ReLU
# Leaky ReLU是为解决“ReLU死亡”问题的尝试。
# ReLU中当x<0时，函数值为0。而Leaky ReLU则是给出一个很小的负数梯度值，比如0.01。
# 所以其函数公式为其中是一个小的常量。有些研究者的论文指出这个激活函数表现很不错，但是其效果并不是很稳定。
# Kaiming He等人在2015年发布的论文Delving Deep into Rectifiers中介绍了一种新方法PReLU，把负区间上的斜率当做每个神经元中的一个参数。
# 然而该激活函数在在不同任务中均有益处的一致性并没有特别清晰。

# Maxout
# 一些其他类型的单元被提了出来，它们对于权重和数据的内积结果不再使用函数形式。
# 一个相关的流行选择是Maxout（最近由Goodfellow等发布）神经元。Maxout是对ReLU和leaky ReLU的一般化归纳，它的函数是：。
# ReLU和Leaky ReLU都是这个公式的特殊情况（比如ReLU就是当的时候）。
# 这样Maxout神经元就拥有ReLU单元的所有优点（线性操作和不饱和），而没有它的缺点（死亡的ReLU单元）。
# 然而和ReLU对比，它每个神经元的参数数量增加了一倍，这就导致整体参数的数量激增。

# 以上就是一些常用的神经元及其激活函数。最后需要注意一点：在同一个网络中混合使用不同类型的神经元是非常少见的，虽然没有什么根本性问题来禁止这样做。

# 一句话：“那么该用那种呢？”用ReLU非线性函数。注意设置好学习率，或许可以监控你的网络中死亡的神经元占的比例。
# 如果单元死亡问题困扰你，就试试Leaky ReLU或者Maxout，不要再用sigmoid了。也可以试试tanh，但是其效果应该不如ReLU或者Maxout。


''' 神经网络结构 '''

# 输出层: 和神经网络中其他层不同, 输出层的神经元一般是不会有激活函数的(或者也可以认为它们有一个线性相等的激活函数)
# 这是因为最后的输出层大多用于表示分类评分值, 因此是任意值的实数, 或者某种实数值的目标数(比如在回归中)

''' 前向传播计算举例 '''

# 不断重复的矩阵乘法与激活函数交织
# 将神经网络组织成层状的一个主要原因, 就是这个结构让神经网络算法使用矩阵向量操作变得简单和高效
# 用3层神经网络举例(3, 4, 4, 1), 输入是[3x1]的向量(一个输入, 如果是批量输入, [3xN], 每个输入样本将会是其中的一列)
# 一个层所有连接的强度可以存在一个单独的矩阵中, 比如第一个隐层的权重 W 1是 [4x3], 所有单元的偏置储存在b1中, 尺寸 [4x1]
# 这样, 每个神经元的权重都在 W1 的一个行中, 于是矩阵乘法 np.dot(W1, x) 就能计算该层中所有神经元的激活数据
# 类似的, W2 将会是 [4x4] 矩阵, 存储着第二个隐层的连接, W3是 [1x4] 的矩阵, 用于输出层
# 完整的3层神经网络的前向传播就是简单的3次矩阵乘法, 其中交织着激活函数的应用

'''

f = lambda x: 1.0/(1.0 + np.exp(-x)) # 激活函数(用的sigmoid)
x = np.random.randn(3, 1) # 含3个数字的随机输入向量(3x1)
h1 = f(np.dot(W1, x) + b1) # 计算第一个隐层的激活数据(4x1)
h2 = f(np.dot(W2, h1) + b2) # 计算第二个隐层的激活数据(4x1)
out = np.dot(W3, h2) + b3 # 神经元输出(1x1)

'''

# 在上面的代码中, W1, W2, W3, b1, b2, b3 都是网络中可以学习的参数
# 注意x并不是一个单独的列向量, 而可以是一个批量的训练数据(其中每个输入样本将会是x中的一列), 所有的样本将会被并行化的高效计算出来
# 注意神经网络最后一层通常是没有激活函数的(例如, 在分类任务中它给出一个实数值的分类评分)

# 全连接层的前向传播一般就是先进行一个矩阵乘法, 然后加上偏置并运用激活函数


''' 表达能力 '''

# 理解具有全连接层的神经网络的一个方式是: 可以认为它们定义了一个由一系列函数组成的函数族, 网络的权重(加偏置)就是每个函数的参数

# 拥有至少一个隐层的神经网络是一个通用的近似器, 神经网络可以近似任何连续函数
# 虽然一个2层网络在数学理论上能完美地近似所有连续函数, 但在实际操作中效果相对较差

# 神经网络在实践中非常好用, 是因为它们表达出的函数不仅平滑, 而且对于数据的统计特性有很好的拟合
# 同时, 网络通过最优化算法(例如梯度下降)能比较容易地学习到这个函数
# 类似的, 虽然在理论上深层网络(使用了多个隐层)和单层网络的表达能力是一样的, 但是就实践经验而言, 深度网络效果比单层网络好

# 在实践中3层的神经网络会比2层的表现好, 然而继续加深(做到4, 5, 6层)很少有太大帮助
# 卷积神经网络的情况却不同, 在卷积神经网络中, 对于一个良好的识别系统来说, 深度是一个极端重要的因素(比如数十(以10为量级)个可学习的层)
# 对于该现象的一种解释观点是: 因为图像拥有层次化结构(比如脸是由眼睛等组成, 眼睛又是由边缘组成), 所以多层处理对于这种数据就有直观意义

''' 设置层的数量和尺寸 '''

# 更多神经元的神经网络可以表达更复杂的函数
# 然而这既是优势也是不足, 优势是可以分类更复杂的数据, 不足是可能造成对训练数据的过拟合

# 过拟合(Overfitting)是网络对数据中的噪声有很强的拟合能力, 而没有重视数据间(假设)的潜在基本关系
# 举例来说, 有20个神经元隐层的网络拟合了所有的训练数据, 但是其代价是把决策边界变成了许多不相连的区域
# 而有3个神经元的模型的表达能力只能用比较宽泛的方式去分类数据, 它将数据看做是两个大块, 并把个别在绿色区域内的红色点看做噪声
# 在实际中，这样可以在测试数据中获得更好的泛化(generalization)能力

# 看起来如果数据不是足够复杂, 则似乎小一点的网络更好, 因为可以防止过拟合
# 然而并非如此, 防止神经网络的过拟合有很多方法(L2正则化, dropout和输入噪音等)
# 在实践中, 使用这些方法来控制过拟合比减少网络神经元数目要好得多

# 不要减少网络神经元数目的主要原因在于小网络更难使用梯度下降等局部方法来进行训练
# 虽然小型网络的损失函数的局部极小值更少, 也比较容易收敛到这些局部极小值, 但是这些最小值一般都很差, 损失值很高
# 相反, 大网络拥有更多的局部极小值, 但就实际损失值来看, 这些局部极小值表现更好, 损失更小
# 因为神经网络是非凸的, 就很难从数学上研究这些特性

# 在实际中, 你将发现如果训练的是一个小网络, 那么最终的损失值将展现出多变性:
# 某些情况下运气好会收敛到一个好的地方, 某些情况下就收敛到一个不好的极值
# 从另一方面来说, 如果你训练一个大的网络, 你将发现许多不同的解决方法, 但是最终损失值的差异将会小很多
# 这就是说, 所有的解决办法都差不多, 而且对于随机初始化参数好坏的依赖也会小很多

# 正则化强度是控制神经网络过拟合的好方法
# 不同正则化强度的效果: 每个神经网络都有20个隐层神经元, 但是随着正则化强度增加, 它的决策边界变得更加平滑
# 需要记住的是: 不应该因为害怕出现过拟合而使用小网络, 相反, 应该进尽可能使用大网络, 然后使用正则化技巧来控制过拟合

# 更大网络总是更好的, 然而更大容量的模型一定要和更强的正则化(比如更高的权重衰减)配合, 否则它们就会过拟合

''' 数据预处理 '''

# 关于数据预处理我们有3个常用的符号, 数据矩阵X, 假设其尺寸是[N x D](N是数据样本的数量, D是数据的维度)

# 均值减法(Mean subtraction)是预处理最常用的形式
# 它对数据中每个独立特征减去平均值, 从几何上可以理解为在每个维度上都将数据云的中心都迁移到原点
# 在numpy中, 该操作可以通过代码 X -= np.mean(X, axis=0)实现
# 而对于图像, 更常用的是对所有像素都减去一个值, 可以用 X -= np.mean(X)实现, 也可以在3个颜色通道上分别操作

# 归一化(Normalization)是指将数据的所有维度都归一化, 使其数值范围都近似相等, 有两种常用方法可以实现归一化
# 第一种是先对数据做零中心化(zero-centered)处理, 然后每个维度都除以其标准差, 实现代码为X /= np.std(X, axis=0)
# 第二种方法是对每个维度都做归一化, 使得每个维度的最大和最小值是1和-1
# 这个预处理操作只有在确信不同的输入特征有不同的数值范围(或计量单位)时才有意义
# 但要注意预处理操作的重要性几乎等同于学习算法本身
# 在图像处理中, 由于像素的数值范围几乎是一致的(都在0-255之间), 所以进行这个额外的预处理步骤并不是很必要

# 一般数据预处理流程: 在每个维度上都减去平均值后得到零中心化数据, 每个维度都除以其标准差来调整其数值范围

# PCA和白化(Whitening)是另一种预处理形式, 在这种处理中, 先对数据进行零中心化处理, 然后计算协方差矩阵, 它展示了数据中的相关性结构
'''

# 假设输入数据矩阵X的尺寸为[N x D]
X -= np.mean(X, axis = 0) # 对数据进行零中心化(重要)
cov = np.dot(X.T, X) / X.shape[0] # 得到数据的协方差矩阵

'''

# 数据协方差矩阵的第(i, j)个元素是数据第i个和第j个维度的协方差
# 具体来说, 该矩阵的对角线上的元素是方差, 还有, 协方差矩阵是对称和半正定的, 我们可以对数据协方差矩阵进行SVD(奇异值分解)运算
'''

U,S,V = np.linalg.svd(cov)

'''

# U的列是特征向量, S是装有奇异值的1维数组(因为cov是对称且半正定的, 所以S中元素是特征值的平方)

# 为了去除数据相关性, 将已经零中心化处理过的原始数据投影到特征基准上:
'''

Xrot = np.dot(X,U) # 对数据去相关性

'''

# 注意U的列是标准正交向量的集合(范式为1, 列之间标准正交), 所以可以把它们看做标准正交基向量
# 因此, 投影对应 x 中的数据的一个旋转, 旋转产生的结果就是新的特征向量, 如果计算 Xrot 的协方差矩阵, 将会看到它是对角对称的
# np.linalg.svd 的一个良好性质是在它的返回值U中, 特征向量是按照特征值的大小排列的
# 我们可以利用这个性质来对数据降维, 只要使用前面的小部分特征向量, 丢弃掉那些包含的数据没有方差的维度
# 这个操作也被称为主成分分析(Principal Component Analysis 简称PCA)降维:
'''

Xrot_reduced = np.dot(X, U[:,:100]) # Xrot_reduced 变成 [N x 100]

'''

# 经过上面的操作, 将原始的数据集的大小由[N x D]降到了[N x 100], 留下了数据中包含最大方差的100个维度
# 通常使用PCA降维过的数据训练线性分类器和神经网络会达到非常好的性能效果, 同时还能节省时间和存储器空间


# 白化(whitening) 白化操作的输入是特征基准上的数据, 然后对每个维度除以其特征值来对数值范围进行归一化
# 该变换的几何解释是: 如果数据服从多变量的高斯分布, 那么经过白化后, 数据的分布将会是一个均值为零, 且协方差相等的矩阵, 该操作的代码如下:
'''

# 对数据进行白化操作:
# 除以特征值
Xwhite = Xrot / np.sqrt(S + 1e-5)

'''

# 夸大的噪声
# 注意分母中添加了1e-5(或一个更小的常量)来防止分母为0, 该变换的一个缺陷是在变换的过程中可能会夸大数据中的噪声
# 这是因为它将所有维度都拉伸到相同的数值范围, 这些维度中也包含了那些只有极少差异性(方差小)而大多是噪声的维度
# 在实际操作中, 这个问题可以用更强的平滑来解决(例如: 采用比1e-5更大的值)

# 常见错误
# 进行预处理很重要的一点是: 任何预处理策略(比如数据均值)都只能在训练集数据上进行计算, 算法训练完毕后再应用到验证集或者测试集上
# 例如, 如果先计算整个数据集图像的平均值然后每张图片都减去平均值, 最后将整个数据集分成训练/验证/测试集, 那么这个做法是错误的
# 应该先分成训练/验证/测试集, 只是从训练集中求图片平均值, 然后各个集(训练/验证/测试集)中的图像再减去这个平均值
# 此处确为初学者常见错误, 请务必注意！


''' 权重初始化 '''

# 错误：全零初始化, 如果权重被初始化为同样的值, 神经元之间就失去了不对称性的源头

# 小随机数初始化
# 因此, 权重初始值要非常接近0又不能等于0, 解决方法就是将权重初始化为很小的数值, 以此来打破对称性
# 其思路是: 如果神经元刚开始的时候是随机且不相等的, 那么它们将计算出不同的更新, 并将自身变成整个网络的不同部分
# 小随机数权重初始化的实现方法是: W = 0.01 * np.random.randn(D,H)
# 其中randn函数是基于零均值和标准差的一个高斯分布(国内教程一般习惯称均值参数为期望μ）来生成随机数的
# 根据这个式子, 每个神经元的权重向量都被初始化为一个随机向量, 而这些随机向量又服从一个多变量高斯分布
# 这样在输入空间中, 所有的神经元的指向是随机的, 也可以使用均匀分布生成的随机数, 但是从实践结果来看, 对于算法的结果影响极小

# 警告: 并不是小数值一定会得到好的结果
# 例如, 一个神经网络的层中的权重值很小, 那么在反向传播的时候就会计算出非常小的梯度(因为梯度与权重值是成比例的)
# 这就会很大程度上减小反向传播中的'梯度信号', 在深度网络中, 就会出现问题

# 使用1/sqrt(n)校准方差
# 上面做法存在一个问题, 随着输入数据量的增长, 随机初始化的神经元的输出数据的分布中的方差也在增大
# 我们可以除以输入数据量的平方根来调整其数值范围, 这样神经元输出的方差就归一化到1了
# 也就是说, 建议将神经元的权重向量初始化为: w = np.random.randn(n) / sqrt(n), 其中n是输入数据的数量
# 这样就保证了网络中所有神经元起始时有近似同样的输出分布, 实践经验证明, 这样做可以提高收敛的速度

# 偏置(biases)的初始化
# 通常将偏置初始化为0, 这是因为随机小数值权重矩阵已经打破了对称性
# 对于ReLU非线性激活函数, 有研究人员喜欢使用如0.01这样的小数值常量作为所有偏置的初始值,
# 这是因为他们认为这样做能让所有的ReLU单元一开始就激活, 这样就能保存并传播一些梯度
# 然而, 这样做是不是总是能提高算法性能并不清楚(有时候实验结果反而显示性能更差), 所以通常还是使用0来初始化偏置参数

# 实践, 当前的推荐是使用ReLU激活函数, 并且使用w = np.random.randn(n) * sqrt(2.0/n)来进行权重初始化

# 批量归一化(Batch Normalization)
# 批量归一化是loffe和Szegedy最近才提出的方法, 该方法减轻了如何合理初始化神经网络这个棘手问题带来的头痛:)
# 其做法是让激活数据在训练开始前通过一个网络, 网络处理数据使其服从标准高斯分布, 因为归一化是一个简单可求导的操作, 所以上述思路是可行的
# 在实现层面, 应用这个技巧通常意味着全连接层(或者是卷积层)与激活函数之间添加一个BatchNorm层
# 在神经网络中使用批量归一化已经变得非常常见, 在实践中, 使用了批量归一化的网络对于不好的初始值有更强的鲁棒性
# 最后一句话总结: 批量归一化可以理解为在网络的每一层之前都做预处理, 只是这种操作以另一种方式与网络集成在了一起


''' 正则化 Regularization '''

# L2正则化可能是最常用的正则化方法了
# 可以通过惩罚目标函数中所有参数的平方将其实现, 即对于网络中的每个权重 w, 向目标函数中增加一个 (1/2) * λ * w**2, 其中 λ 是正则化强度
# 前面这个 1/2 很常见, 是因为加上 1/2 后, 该式子关于 w 梯度就是 λ * w 而不是 2 * λ * w 了
# L2正则化可以直观理解为它对于大数值的权重向量进行严厉惩罚, 倾向于更加分散的权重向量
# 在线性分类章节中讨论过，由于输入和权重之间的乘法操作, 这样就有了一个优良的特性:
# 使网络更倾向于使用所有输入特征, 而不是严重依赖输入特征中某些小部分特征
# 最后需要注意在梯度下降和参数更新的时候, 使用L2正则化意味着所有的权重都以 w += -lambda * W 向着0线性下降

# L1正则化是另一个相对常用的正则化方法
# 对于每个 w 我们都向目标函数增加一个 λ * |w|
# L1和L2正则化也可以进行组合: λ1 * |w| + λ2 * w**2, 这也被称作Elastic net regularizaton
# L1正则化有一个有趣的性质, 它会让权重向量在最优化的过程中变得稀疏(即非常接近0)
# 也就是说, 使用L1正则化的神经元最后使用的是它们最重要的输入数据的稀疏子集, 同时对于噪音输入则几乎是不变的了
# 相较L1正则化, L2正则化中的权重向量大多是分散的小数字,
# 在实践中, 如果不是特别关注某些明确的特征选择, 一般说来L2正则化都会比L1正则化效果好

# 最大范式约束(Max norm constraints)
# 另一种形式的正则化是给每个神经元中权重向量的量级设定上限, 并使用投影梯度下降来确保这一约束
# 在实践中, 与之对应的是参数更新方式不变, 然后要求神经元中的权重向量 w 必须满足 ||w||2 < c 这一条件, 一般 c 值为3或者4
# 有研究者发文称在使用这种正则化方法时效果更好,
# 这种正则化还有一个良好的性质, 即使在学习率设置过高的时候, 网络中也不会出现数值'爆炸', 这是因为它的参数更新始终是被限制着的

# 随机失活(Dropout)是一个简单又极其有效的正则化方法
# 与L1正则化, L2正则化和最大范式约束等方法互为补充, 在训练的时候, 随机失活的实现方法是让神经元以超参数的概率被激活或者被设置为0
# 在训练过程中, 随机失活可以被认为是对完整的神经网络抽样出一些子集,
# 每次基于输入数据只更新子网络的参数(然而, 数量巨大的子网络们并不是相互独立的, 因为它们都共享参数)
# 在测试过程中不使用随机失活, 可以理解为是对数量巨大的子网络们做了模型集成(model ensemble), 以此来计算出一个平均的预测

# 一个3层神经网络的普通版随机失活可以用下面代码实现:
'''

""" 普通版随机失活: 不推荐实现 """

p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  """ X中是输入数据 """

  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = np.random.rand(*H1.shape) < p # 第一个随机失活遮罩
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = np.random.rand(*H2.shape) < p # 第二个随机失活遮罩
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3

  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)

def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # 注意：激活数据要乘以p
  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # 注意：激活数据要乘以p
  out = np.dot(W3, H2) + b3

'''

# 在上面的代码中, train_step函数在第一个隐层和第二个隐层上进行了两次随机失活
# 在输入层上面进行随机失活也是可以的, 为此需要为输入数据 X 创建一个二值的遮罩
# 反向传播保持不变, 但是肯定需要将遮罩U1和U2加入进去

# 注意: 在predict函数中不进行随机失活, 但是对于两个隐层的输出都要乘以 p, 调整其数值范围
# 这一点非常重要, 因为在测试时所有的神经元都能看见它们的输入, 因此我们想要神经元的输出与训练时的预期输出是一致的
# 以 p = 0.5 为例, 在测试时神经元必须把它们的输出减半, 这是因为在训练的时候它们的输出只有一半
# 为了理解这点, 先假设有一个神经元 x 的输出, 那么进行随机失活的时候, 该神经元的输出就是 p * x + (1 - p) * 0
# 有 1 - p 的概率神经元的输出为0, 在测试时神经元总是激活的, 就必须调整 x -> p * x 来保持同样的预期输出
# 在测试时会在所有可能的二值遮罩(也就是数量庞大的所有子网络)中迭代并计算它们的协作预测, 进行这种减弱的操作也可以认为是与之相关的

# 上述操作不好的性质是必须在测试时对激活数据要按照 p 进行数值范围调整
# 既然测试性能如此关键, 实际更倾向使用反向随机失活(inverted dropout), 它是在训练时就进行数值范围调整, 从而让前向传播在测试时保持不变
# 这样做还有一个好处, 无论你决定是否使用随机失活, 预测方法的代码可以保持不变, 反向随机失活的代码如下:
'''

"""
反向随机失活: 推荐实现方式.
在训练的时候drop和调整数值范围，测试时不做任何事.
"""

p = 0.5 # 激活神经元的概率. p值更高 = 随机失活更弱

def train_step(X):
  # 3层neural network的前向传播
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = (np.random.rand(*H1.shape) < p) / p # 第一个随机失活遮罩. 注意/p!
  H1 *= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = (np.random.rand(*H2.shape) < p) / p # 第二个随机失活遮罩. 注意/p!
  H2 *= U2 # drop!
  out = np.dot(W3, H2) + b3

  # 反向传播:计算梯度... (略)
  # 进行参数更新... (略)

def predict(X):
  # 前向传播时模型集成
  H1 = np.maximum(0, np.dot(W1, X) + b1) # 不用数值范围调整了
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  out = np.dot(W3, H2) + b3

'''

# 前向传播中的噪音
# 在更一般化的分类上, 随机失活属于网络在前向传播中有随机行为的方法
# 测试时, 通过分析法(在使用随机失活的本例中就是乘以 p)或数值法(例如通过抽样出很多子网络, 随机选择不同子网络进行前向传播, 最后取平均)
# 将噪音边缘化, 在这个方向上的另一个研究是DropConnect, 它在前向传播的时候, 一系列权重被随机设置为0
# 卷积神经网络同样会吸取这类方法的优点,
# 比如随机汇合(stochastic pooling), 分级汇合(fractional pooling), 数据增长(data augmentation)

# 偏置正则化
# 对于偏置参数的正则化并不常见, 因为它们在矩阵乘法中和输入数据并不产生互动, 所以并不需要控制其在数据维度上的效果
# 然而在实际应用中(使用了合理数据预处理的情况下), 对偏置进行正则化也很少会导致算法性能变差
# 这可能是因为相较于权重参数, 偏置参数实在太少, 所以分类器需要它们来获得一个很好的数据损失, 那么还是能够承受的

# 每层正则化
# 对于不同的层进行不同强度的正则化很少见(可能除了输出层以外), 关于这个思路的相关文献也很少

# 实践: 通过交叉验证获得一个全局使用的L2正则化强度是比较常见的
# 在使用L2正则化的同时在所有层后面使用随机失活也很常见, p 值一般默认设为0.5, 也可在验证集上调参

''' 损失函数 '''

# 损失函数的第一部分是正则化损失部分, 它可以看做是对模型复杂程度的某种惩罚
# 损失函数的第二部分是数据损失, 它是一个有监督学习问题, 用于衡量分类算法的预测结果(即分类评分)和真实标签结果之间的一致性

# 数据损失是对所有样本的数据损失求平均, 也就是说，L = 1/N * sum(Li), N是训练集数据的样本数
# 让我们把神经网络中输出层的激活函数简写为 f = f(xi; W), 在实际中你可能需要解决以下几类问题:

# 分类问题
# 在该问题中, 假设有一个装满样本的数据集, 每个样本都有一个唯一的正确标签(是固定分类标签之一)
# 在这类问题中, 一个最常见的损失函数就是SVM(是Weston Watkins 公式):
# Li = sum(max(0, fj - fyi +1), j!=yi)
# 有些学者的论文中指出平方折叶损失( 即使用 max(0, fj-fyi+1)^2 )算法的结果会更好

# 第二个常用的损失函数是Softmax分类器, 它使用交叉熵损失:
# Li = -log(e^fyi / sum(e^fj, j)) = -np.log10(softmax)

# 问题:类别数目巨大
# 当标签集非常庞大(例如字典中的所有英语单词, 或者ImageNet中的22000种分类), 就需要使用分层Softmax(Hierarchical Softmax)了
# 分层softmax将标签分解成一个树, 每个标签都表示成这个树上的一个路径, 这个树的每个节点处都训练一个Softmax分类器来在左和右分枝之间做决策
# 树的结构对于算法的最终结果影响很大, 而且一般需要具体问题具体分析

# 属性(Attribute)分类
# 上面两个损失公式的前提, 都是假设每个样本只有一个正确的标签 yi
# 但是如果 yi 是一个二值向量, 每个样本可能有, 也可能没有某个属性, 而且属性之间并不相互排斥呢?
# 比如在Instagram上的图片, 就可以看成是被一个巨大的标签集合中的某个子集打上标签, 一张图片上可能有多个标签
# 在这种情况下, 一个明智的方法是为每个属性创建一个独立的二分类的分类器, 例如, 针对每个分类的二分类器会采用下面的公式:
# Li = sum(max(0, 1 - yij * fj), j)
# 上式中, 求和是对所有分类 j, yij的值为1或者-1, 具体根据第i个样本是否被第j个属性打标签而定
# 当该类别被正确预测并展示的时候, 分值向量 fj 为正, 其余情况为负
# 可以发现, 当一个正样本的得分小于+1, 或者一个负样本得分大于-1的时候, 算法就会累计损失值

# 另一种方法是对每种属性训练一个独立的逻辑回归分类器, 二分类的逻辑回归分类器只有两个分类(0, 1), 其中对于分类1的概率计算为:
# P(y = 1 | x; w, b) = 1 / (1 + e^(-1 * (w.T * x + b))) = σ(w.T * x + b)

# 因为类别0和类别1的概率和为1, 所以类别0的概率为:
# P(y = 0 | x; w, b) = 1 - P(y = 1 | x; w, b)
# 这样, 如果 σ(w.T * x + b) > 0.5 或者 w.T * x + b > 0, 那么样本就要被分类成为正样本(y=1)
# 然后损失函数最大化这个对数似然函数, 问题可以简化为:
# Li = sum(yij * log(σ(fj)) + (1 - yij) * log(1 - σ(fj)), j)
# 上式中, 假设标签 yij 非0即1, σ(.)就是sigmoid函数, 上面的公式看起来吓人, 但是 f 的梯度实际上非常简单:
# dLi/dfj = yij - σ(fj)

# 回归问题是预测实数的值的问题, 比如预测房价, 预测图片中某个东西的长度等
# 对于这种问题, 通常是计算预测值和真实值之间的损失, 然后用L2平方范式或L1范式度量差异, 对于某个样本, L2范式计算如下:
# Li = ||f - yi|| 2,2
# 之所以在目标函数中要进行平方, 是因为梯度算起来更加简单, 因为平方是一个单调运算, 所以不用改变最优参数
# L1范式则是要将每个维度上的绝对值加起来:
# Li = ||f - yi|| 1 = sum(|fi - (yi)j|, j)

# 在上式中, 如果有多个数量被预测了, 就要对预测的所有维度的预测求和, 即 sum(_, j)
# 观察第i个样本的第j维, 用 δij 表示预测值与真实值之间的差异
# 关于该维度的梯度(也就是 dLi/dfj)能够轻松地通过被求导为L2范式的 δij 或 sign(δij)
# 这就是说, 评分值的梯度要么与误差中的差值直接成比例, 要么是固定的并从差值中继承sign

# 注意: L2损失比起较为稳定的Softmax损失来, 其最优化过程要困难很多
# 直观而言, 它需要网络具备一个特别的性质, 即对于每个输入(和增量)都要输出一个确切的正确值
# 而在Softmax中就不是这样, 每个评分的准确值并不是那么重要: 只有当它们量级适当的时候, 才有意义
# 还有, L2损失鲁棒性不好, 因为异常值可以导致很大的梯度
# 所以在面对一个回归问题时, 先考虑将输出变成二值化是否真的不够用
# 例如，如果对一个产品的星级进行预测, 使用5个独立的分类器来对1-5星进行打分的效果一般比使用一个回归损失要好很多
# 分类还有一个额外优点, 就是能给出关于回归的输出的分布, 而不是一个简单的毫无把握的输出值
# 如果确信分类不适用, 那么使用L2损失吧, 但是一定要谨慎: L2非常脆弱, 在网络中使用随机失活(尤其是在L2损失层的上一层)不是好主意

# 当面对一个回归任务, 首先考虑是不是必须这样, 一般而言, 尽量把你的输出变成二分类, 然后对它们进行分类, 从而变成一个分类问题

# 结构化预测(structured prediction)
# 结构化损失是指标签可以是任意的结构, 例如图表, 树或者其他复杂物体的情况
# 通常这种情况还会假设结构空间非常巨大, 不容易进行遍历
# 结构化SVM背后的基本思想就是在正确的结构 yi 和得分最高的非正确结构之间画出一个边界
# 解决这类问题, 并不是像解决一个简单无限制的最优化问题那样使用梯度下降就可以了, 而是需要设计一些特殊的解决方案
# 这样可以有效利用对于结构空间的特殊简化假设

''' 梯度检查 '''

# 理论上将进行梯度检查很简单, 就是简单地把解析梯度和数值计算梯度进行比较, 然而从实际操作层面上来说, 这个过程更加复杂且容易出错

# 使用中心化公式
# 在使用有限差值近似来计算数值梯度的时候, 常见的公式是:
# df(x)/dx = (f(x + h) - f(x)) / h (bad, do not use)
# 其中h是一个很小的数字, 在实践中近似为1e-5
# 实践证明, 使用中心化公式效果更好:
# df(x)/dx = (f(x + h) - f(x - h)) / 2*h (use)
# 该公式在检查梯度的每个维度的时候, 会要求计算两次损失函数(所以计算资源的耗费也是两倍), 但是梯度的近似值会准确很多
# 要理解这一点, 对 f(x+h) 和 f(x-h) 使用泰勒展开, 可以看到第一个公式的误差近似 O(h), 第二个公式的误差近似 O(h^2)(是个二阶近似)
# 泰勒展开相关内容可阅读《高等数学》第十二章第四节: 函数展开成幂级数

# 使用相对误差来比较
# 比较数值梯度 dfn 和解析梯度 dfa 的细节有哪些? 如何得知此两者不匹配?
# 你可能会倾向于监测它们的差的绝对值 |dfa - dfn| 或者差的平方值, 然后定义该值如果超过某个规定阈值, 就判断梯度实现失败
# 然而该思路是有问题的, 想想, 假设这个差值是1e-4, 如果两个梯度值在1.0左右, 这个差值看起来就很合适, 可以认为两个梯度是匹配的
# 然而如果梯度值是1e-5或者更低, 那么1e-4就是非常大的差距, 梯度实现肯定就是失败的了, 因此, 使用相对误差总是更合适一些:
# |dfa - dfn| / max(|dfa|, |dfn|)
# 上式考虑了差值占两个梯度绝对值的比例, 注意通常相对误差公式只包含两个式子中的一个(任意一个均可)
# 但是我更倾向取两个式子的最大值或者取两个式子的和, 这样做是为了防止在其中一个式子为0时, 公式分母为0(这种情况, 在ReLU中是经常发生的)
# 然而, 还必须注意两个式子都为零且通过梯度检查的情况, 在实践中:
# 相对误差>1e-2: 通常就意味着梯度可能出错
# 1e-2>相对误差>1e-4: 要对这个值感到不舒服才行
# 1e-4>相对误差: 这个值的相对误差对于有不可导点的目标函数是OK的, 但如果目标函数中没有kink(使用tanh和softmax), 那么相对误差值还是太高
# 1e-7或者更小: 好结果, 可以高兴一把了
# 要知道的是网络的深度越深, 相对误差就越高
# 所以如果你是在对一个10层网络的输入数据做梯度检查, 那么1e-2的相对误差值可能就OK了, 因为误差一直在累积
# 相反, 如果一个可微函数的相对误差值是1e-2, 那么通常说明梯度实现不正确

# 使用双精度
# 一个常见的错误是使用单精度浮点数来进行梯度检查, 这样会导致即使梯度实现正确, 相对误差值也会很高(比如1e-2)
# 在我的经验而言, 出现过使用单精度浮点数时相对误差为1e-2, 换成双精度浮点数时就降低为1e-8的情况

# 保持在浮点数的有效范围
# 建议通读《What Every Computer Scientist Should Know About Floating-Point Arithmetic》一文
# 该文将阐明你可能犯的错误, 促使你写下更加细心的代码, 例如, 在神经网络中, 在一个批量的数据上对损失函数进行归一化是很常见的
# 但是, 如果每个数据点的梯度很小, 然后又用数据点的数量去除, 就使得数值更小, 这反过来会导致更多的数值问题
# 这就是我为什么总是会把原始的解析梯度和数值梯度数据打印出来, 确保用来比较的数字的值不是过小(通常绝对值小于1e-10就绝对让人担心)
# 如果确实过小, 可以使用一个常数暂时将损失函数的数值范围扩展到一个更'好'的范围, 在这个范围中浮点数变得更加致密
# 比较理想的是1.0的数量级上, 即当浮点数指数为0时

# 目标函数的不可导点(kinks)
# 在进行梯度检查时, 一个导致不准确的原因是不可导点问题
# 不可导点是指目标函数不可导的部分, 由ReLU(max(0, x))等函数, 或SVM损失, Maxout神经元等引入
# 考虑当 x = -1e6 时, 对ReLU函数进行梯度检查, 因为 x < 0, 所以解析梯度在该点的梯度为0,
# 然而, 在这里数值梯度会突然计算出一个非零的梯度值, 因为 f(x + h) 可能越过了不可导点(例如: 如果 h > 1e-6), 导致了一个非零的结果
# 你可能会认为这是一个极端的案例, 但实际上这种情况很常见
# 例如, 一个用CIFAR-10训练的SVM中, 因为有50,000个样本, 且根据目标函数每个样本产生9个式子, 所以包含有450,000个 max(0, x) 式子
# 而一个用SVM进行分类的神经网络因为采用了ReLU, 还会有更多的不可导点
# 注意, 在计算损失的过程中是可以知道不可导点有没有被越过的
# 在具有 max(x, y) 形式的函数中持续跟踪所有'赢家'的身份, 就可以实现这一点
# 其实就是看在前向传播时, 到底 x 和 y 谁更大, 如果在计算和的时候m 至少有一个'赢家'的身份变了, 那就说明不可导点被越过了, 数值梯度会不准确

# 使用少量数据点
# 解决上面的不可导点问题的一个办法是使用更少的数据点
# 因为含有不可导点的损失函数(例如: 因为使用了ReLU或者边缘损失等函数)的数据点越少, 不可导点就越少
# 所以在计算有限差值近似时越过不可导点的几率就越小, 还有, 如果你的梯度检查对2-3个数据点都有效
# 那么基本上对整个批量数据进行梯度检查也是没问题的, 所以使用很少量的数据点, 能让梯度检查更迅速高效

# 谨慎设置步长h
# 在实践中h并不是越小越好, 因为当h特别小的时候, 就可能就会遇到数值精度问题
# 有时候如果梯度检查无法进行, 可以试试将h调到1e-4或者1e-6, 然后突然梯度检查可能就恢复正常

# 在操作的特性模式中梯度检查
# 有一点必须要认识到: 梯度检查是在参数空间中的一个特定(往往还是随机的)的单独点进行的
# 即使是在该点上梯度检查成功了, 也不能马上确保全局上梯度的实现都是正确的
# 还有, 一个随机的初始化可能不是参数空间最优代表性的点, 这可能导致进入某种病态的情况, 即梯度看起来是正确实现了, 实际上并没有
# 例如, SVM使用小数值权重初始化, 就会把一些接近于0的得分分配给所有的数据点, 而梯度将会在所有的数据点上展现出某种模式
# 一个不正确实现的梯度也许依然能够产生出这种模式, 但是不能泛化到更具代表性的操作模式
# 比如在一些的得分比另一些得分更大的情况下就不行, 因此为了安全起见, 最好让网络学习('预热')一小段时间, 等到损失函数开始下降的之后再进行梯度检查
# 在第一次迭代就进行梯度检查的危险就在于, 此时可能正处在不正常的边界情况, 从而掩盖了梯度没有正确实现的事实

# 不要让正则化吞没数据
# 通常损失函数是数据损失和正则化损失的和(例如L2对权重的惩罚)
# 需要注意的危险是正则化损失可能吞没掉数据损失, 在这种情况下梯度主要来源于正则化部分(正则化部分的梯度表达式通常简单很多)
# 这样就会掩盖掉数据损失梯度的不正确实现, 因此, 推荐先关掉正则化对数据损失做单独检查, 然后对正则化做单独检查
# 对于正则化的单独检查可以是修改代码, 去掉其中数据损失的部分, 也可以提高正则化强度, 确认其效果在梯度检查中是无法忽略的
# 这样不正确的实现就会被观察到了

# 记得关闭随机失活(dropout)和数据扩张(augmentation)
# 在进行梯度检查时, 记得关闭网络中任何不确定的效果的操作, 比如随机失活, 随机数据扩展等
# 不然它们会在计算数值梯度的时候导致巨大误差, 关闭这些操作不好的一点是无法对它们进行梯度检查(例如随机失活的反向传播实现可能有错误)
# 因此, 一个更好的解决方案就是在计算和前强制增加一个特定的随机种子, 在计算解析梯度时也同样如此

# 检查少量的维度
# 在实际中, 梯度可以有上百万的参数, 在这种情况下只能检查其中一些维度然后假设其他维度是正确的
# 注意: 确认在所有不同的参数中都抽取一部分来梯度检查
# 在某些应用中, 为了方便, 人们将所有的参数放到一个巨大的参数向量中, 在这种情况下, 例如偏置就可能只占用整个向量中的很小一部分
# 所以不要随机地从向量中取维度, 一定要把这种情况考虑到, 确保所有参数都收到了正确的梯度

''' 合理性检查 '''

# 寻找特定情况的正确损失值
# 在使用小参数进行初始化时, 确保得到的损失值与期望一致, 最好先单独检查数据损失(让正则化强度为0)
# 例如, 对于一个跑CIFAR-10的Softmax分类器, 一般期望它的初始损失值是2.302, 这是因为初始时预计每个类别的概率是0.1(因为有10个类别)
# 然后Softmax损失值正确分类的负对数概率: -ln(0.1)=2.302
# 对于Weston Watkins SVM, 假设所有的边界都被越过(因为所有的分值都近似为零), 所以损失值是9(因为对于每个错误分类, 边界值是1)
# 如果没看到这些损失值, 那么初始化中就可能有问题

# 提高正则化强度时导致损失值变大

# 对小数据子集过拟合
# 最后也是最重要的一步, 在整个数据集进行训练之前, 尝试在一个很小的数据集上进行训练(比如20个数据), 然后确保能到达0的损失值
# 进行这个实验的时候, 最好让正则化强度为0, 不然它会阻止得到0的损失, 除非能通过这一个正常性检查, 不然进行整个数据集训练是没有意义的
# 但是注意, 能对小数据集进行过拟合并不代表万事大吉, 依然有可能存在不正确的实现
# 比如, 因为某些错误, 数据点的特征是随机的, 这样算法也可能对小数据进行过拟合, 但是在整个数据集上跑算法的时候, 就没有任何泛化能力

''' 检查整个学习过程 '''

# 在训练神经网络的时候, 应该跟踪多个重要数值, 这些数值输出的图表是观察训练进程的一扇窗口, 是直观理解不同的超参数设置效果的工具
# 从而知道如何修改超参数以获得更高效的学习过程

# x轴通常都是表示周期(epochs)单位, 该单位衡量了在训练中每个样本数据都被观察过次数的期望(一个周期意味着每个样本数据都被观察过了一次)
# 相较于迭代次数(iterations), 一般更倾向跟踪周期, 这是因为迭代次数与数据的批尺寸(batchsize)有关, 而批尺寸的设置又可以是任意的

# 训练期间第一个要跟踪的数值就是损失值, 它在前向传播时对每个独立的批数据进行计算
# 过低的学习率导致算法的改善是线性的
# 高一些的学习率会看起来呈几何指数下降
# 更高的学习率会让损失值很快下降, 但是接着就停在一个不好的损失值上

# 损失值的震荡程度和批尺寸(batch size)有关, 当批尺寸为1, 震荡会相对较大
# 当批尺寸是整个数据集时震荡就会最小, 因为每个梯度更新都是单调地优化损失函数(除非学习率设置得过高)

# 在训练分类器的时候, 需要跟踪的第二重要的数值是验证集和训练集的准确率
# 在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度
# 相较于训练集, 验证集的准确率低了很多, 这就说明模型有很强的过拟合
# 遇到这种情况, 就应该增大正则化强度(更强的L2权重惩罚, 更多的随机失活等)或收集更多的数据
# 验证集曲线和训练集曲线如影随形, 这种情况说明你的模型容量还不够大: 应该通过增加参数数量让模型容量更大些

# 最后一个应该跟踪的量是权重中更新值的数量和全部值的数量之间的比例
# 注意: 是更新的, 而不是原始梯度(比如, 在普通sgd中就是梯度乘以学习率), 需要对每个参数集的更新比例进行单独的计算和跟踪
# 一个经验性的结论是这个比例应该在1e-3左右, 如果更低, 说明学习率可能太小, 如果更高, 说明学习率可能太高
'''

# 假设参数向量为W，其梯度向量为dW
param_scale = np.linalg.norm(W.ravel())
update = -learning_rate*dW # 简单SGD更新
update_scale = np.linalg.norm(update.ravel())
W += update # 实际更新
print update_scale / param_scale # 要得到1e-3左右

'''

# 相较于跟踪最大和最小值, 有研究者更喜欢计算和跟踪梯度的范式及其更新, 这些矩阵通常是相关的, 也能得到近似的结果

# 每层的激活数据及梯度分布
# 一个不正确的初始化可能让学习过程变慢, 甚至彻底停止, 还好, 这个问题可以比较简单地诊断出来
# 其中一个方法是输出网络中所有层的激活数据和梯度分布的柱状图, 直观地说, 就是如果看到任何奇怪的分布情况, 那都不是好兆头
# 比如, 对于使用tanh的神经元, 我们应该看到激活数据的值在整个[-1,1]区间中都有分布
# 如果看到神经元的输出全部是0, 或者全都饱和了往-1和1上跑, 那肯定就是有问题了

# 第一层可视化
# 如果数据是图像像素数据，那么把第一层特征可视化会有帮助


''' 参数更新 '''

# 普通更新
# 最简单的更新形式是沿着负梯度方向改变参数(因为梯度指向的是上升方向, 但是我们通常希望最小化损失函数)
# 假设有一个参数向量x及其梯度dx, 那么最简单的更新的形式是:
'''

# 普通更新
x += - learning_rate * dx

'''
# 其中learning_rate是一个超参数, 它是一个固定的常量, 当在整个数据集上进行计算时, 只要学习率足够低, 总是能在损失函数上得到非负的进展

# 动量(Momentum)更新
# 这个方法在深度网络上几乎总能得到更好的收敛速度, 该方法可以看成是从物理角度上对于最优化问题得到的启发
# 损失值可以理解为是山的高度(因此高度势能是 U = mgh, 所以有 U∝h）
# 用随机数字初始化参数等同于在某个位置给质点设定初始速度为0, 这样最优化过程可以看做是模拟参数向量(即质点)在地形上滚动的过程
# 因为作用于质点的力与梯度的潜在能量(F = -∇U)有关, 质点所受的力就是损失函数的(负)梯度
# 还有, 因为 F = ma, 所以在这个观点下(负)梯度与质点的加速度是成比例的
# 注意这个理解和上面的随机梯度下降(SDG)是不同的, 在普通版本中, 梯度直接影响位置
# 而在这个版本的更新中, 物理观点建议梯度只是影响速度, 然后速度再影响位置:
'''

# 动量更新
v = mu * v - learning_rate * dx # 与速度融合
x += v # 与位置融合

'''
# 在这里引入了一个初始化为0的变量 v 和一个超参数 mu
# 说得不恰当一点, 这个变量(mu)在最优化的过程中被看做动量(一般值设为0.9), 但其物理意义与摩擦系数更一致
# 这个变量有效地抑制了速度, 降低了系统的动能, 不然质点在山底永远不会停下来
# 通过交叉验证, 这个参数通常设为[0.5, 0.9, 0.95, 0.99]中的一个, 和学习率随着时间退火类似
# 动量随时间变化的设置有时能略微改善最优化的效果, 其中动量在学习过程的后阶段会上升
# 一个典型的设置是刚开始将动量设为0.5, 而在后面的多个周期(epoch)中慢慢提升到0.99

# 通过动量更新, 参数向量会在任何有持续梯度的方向上增加速度

# Nesterov动量
# 与普通动量有些许不同, 最近变得比较流行
# 在理论上对于凸函数它能得到更好的收敛, 在实践中也确实比标准动量表现更好一些
# Nesterov动量的核心思路是, 当参数向量位于某个位置 x 时, 观察上面的动量更新公式可以发现
# 动量部分(忽视带梯度的第二个部分)会通过 mu * v 稍微改变参数向量
# 因此, 如果要计算梯度, 那么可以将未来的近似位置 x + mu * v 看做是'向前看', 这个点在我们一会儿要停止的位置附近
# 因此, 计算 x + mu * v 的梯度而不是'旧'位置 x 的梯度就有意义了
# 使用Nesterov动量，我们就在这个'向前看'的地方计算梯度
'''

x_ahead = x + mu * v
# 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)
v = mu * v - learning_rate * dx_ahead
x += v

'''
# 然而在实践中, 人们更喜欢和普通SGD或上面的动量方法一样简单的表达式
# 通过对 x_ahead = x + mu * v 使用变量变换进行改写是可以做到的, 然后用x_ahead而不是x来表示上面的更新
# 也就是说, 实际存储的参数向量总是向前一步的那个版本, x_ahead的公式(将其重新命名为x)就变成了:
'''

v_prev = v # 存储备份
v = mu * v - learning_rate * dx # 速度更新保持不变
x += -mu * v_prev + (1 + mu) * v # 位置更新变了形式

'''

''' 学习率退火 '''

# 在训练深度网络的时候, 让学习率随着时间退火通常是有帮助的
# 可以这样理解: 如果学习率很高, 系统的动能就过大, 参数向量就会无规律地跳动, 不能够稳定到损失函数更深更窄的部分去
# 知道什么时候开始衰减学习率是有技巧的: 慢慢减小它, 可能在很长时间内只能是浪费计算资源地看着它混沌地跳动, 实际进展很少
# 但如果快速地减少它, 系统可能过快地失去能量, 不能到达原本可以到达的最好位置
# 通常, 实现学习率退火有3种方式:

# 随步数衰减
# 每进行几个周期就根据一些因素降低学习率, 典型的值是每过5个周期就将学习率减少一半, 或者每20个周期减少到之前的0.1
# 这些数值的设定是严重依赖具体问题和模型的选择的, 在实践中可能看见这么一种经验做法:
# 使用一个固定的学习率来进行训练的同时观察验证集错误率, 每当验证集错误率停止下降, 就乘以一个常数(比如0.5)来降低学习率

# 指数衰减
# 数学公式是 α = α0 * e**(−ktα), 其中α0, k是超参数, t是迭代次数(也可以使用周期作为单位)

# 1/t衰减
# 数学公式是 α = α0 / (1 + kt), 其中α0, k是超参数, t是迭代次数

# 在实践中, 我们发现随步数衰减的随机失活(dropout)更受欢迎, 因为它使用的超参数(衰减系数和以周期为时间单位的步数)比k更有解释性
# 最后, 如果你有足够的计算资源, 可以让衰减更加缓慢一些, 让训练时间更长些


''' 二阶方法 '''

# 深度网络背景下, 第二类常用的最优化方法是基于牛顿法的, 其迭代如下:
# x  <-  x − [Hf(x)]**−1 * ∇f(x)

# 这里 Hf(x) 是Hessian矩阵, 它是函数的二阶偏导数的平方矩阵, ∇f(x)是梯度向量，这和梯度下降中一样
# 直观理解上, Hessian矩阵描述了损失函数的局部曲率, 从而使得可以进行更高效的参数更新
# 具体来说, 就是乘以Hessian转置矩阵可以让最优化过程在曲率小的时候大步前进, 在曲率大的时候小步前进
# 需要重点注意的是, 在这个公式中是没有学习率这个超参数的, 这相较于一阶方法是一个巨大的优势

# 然而上述更新方法很难运用到实际的深度学习应用中去, 这是因为计算(以及求逆)Hessian矩阵操作非常耗费时间和空间
# 举例来说, 假设一个有一百万个参数的神经网络, 其Hessian矩阵大小就是[1,000,000 x 1,000,000], 将占用将近3725GB的内存
# 这样, 各种各样的拟-牛顿法就被发明出来用于近似转置Hessian矩阵
# 在这些方法中最流行的是L-BFGS, 该方法使用随时间的梯度中的信息来隐式地近似(也就是说整个矩阵是从来没有被计算的)

# 然而, 即使解决了存储空间的问题, L-BFGS应用的一个巨大劣势是需要对整个训练集进行计算, 而整个训练集一般包含几百万的样本
# 和小批量随机梯度下降(mini-batch SGD)不同, 让L-BFGS在小批量上运行起来是很需要技巧, 同时也是研究热点

# 在深度学习和卷积神经网络中, 使用L-BFGS之类的二阶方法并不常见
# 相反, 基于(Nesterov的)动量更新的各种随机梯度下降方法更加常用, 因为它们更加简单且容易扩展

''' 逐参数适应学习率方法 '''

# Adagrad
'''

# 假设有梯度和参数向量x
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)

'''
# 注意, 变量cache的尺寸和梯度矩阵的尺寸是一样的, 还跟踪了每个参数的梯度的平方和
# 这个一会儿将用来归一化参数更新步长, 归一化是逐元素进行的
# 注意, 接收到高梯度值的权重更新的效果被减弱, 而接收到低梯度值的权重的更新效果将会增强
# 有趣的是平方根的操作非常重要, 如果去掉, 算法的表现将会糟糕很多
# 用于平滑的式子eps(一般设为1e-4到1e-8之间)是防止出现除以0的情况
# Adagrad的一个缺点是, 在深度学习中单调的学习率被证明通常过于激进且过早停止学习

# RMSprop
# 这个方法用一种很简单的方式修改了Adagrad方法, 让它不那么激进, 单调地降低了学习率, 具体说来, 就是它使用了一个梯度平方的滑动平均:
'''

cache =  decay_rate * cache + (1 - decay_rate) * dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)

'''
# 在上面的代码中, decay_rate是一个超参数, 常用的值是[0.9, 0.99, 0.999], 其中 x += 和Adagrad中是一样的, 但是cache变量是不同的
# 因此, RMSProp仍然是基于梯度的大小来对每个权重的学习率进行修改, 这同样效果不错, 但是和Adagrad不同, 其更新不会让学习率单调变小

# Adam
# 它看起来像是RMSProp的动量版, 简化的代码是下面这样:
'''

m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)

'''
# 注意, 这个更新方法看起来真的和RMSProp很像, 除了使用的是平滑版的梯度 m, 而不是用的原始梯度向量dx
# 论文中推荐的参数值 eps=1e-8, beta1=0.9, beta2=0.999
# 在实际操作中, 我们推荐Adam作为默认的算法, 一般而言跑起来比RMSProp要好一点, 但是也可以试试SGD+Nesterov动量
# 完整的Adam更新算法也包含了一个偏置(bias)矫正机制, 因为 m, v两个矩阵初始为0, 在没有完全热身之前存在偏差, 需要采取一些补偿措施

# 注意SGD很难突破对称性, 而RMSProp之类的方法能够看到马鞍方向有很低的梯度
# 因为在RMSProp更新方法中的分母项, 算法提高了在该方向的有效学习率, 使得RMSProp能够继续前进


''' 超参数调优 '''

# 训练一个神经网络会遇到很多超参数设置, 神经网络最常用的设置有:
# 初始学习率
# 学习率衰减方式(例如一个衰减常量)
# 正则化强度(L2惩罚, 随机失活强度)

# 还有很多相对不那么敏感的超参数, 比如在逐参数适应学习方法中, 对于动量及其时间表的设置等

# 更大的神经网络需要更长的时间去训练, 所以调参可能需要几天甚至几周
# 记住这一点很重要, 因为这会影响你设计代码的思路, 一个具体的设计是用 仆程序 持续地随机设置参数然后进行最优化
# 在训练过程中, 仆程序会对每个周期后验证集的准确率进行监控, 然后向文件系统写下一个模型的记录点
# (记录点中有各种各样的训练统计数据, 比如随着时间的损失值变化等), 这个文件系统最好是可共享的
# 在文件名中最好包含验证集的算法表现, 这样就能方便地查找和排序了
# 然后还有一个主程序, 它可以启动或者结束计算集群中的仆程序, 有时候也可能根据条件查看仆程序写下的记录点, 输出它们的训练统计数据等

# 比起交叉验证最好使用一个验证集
# 在大多数情况下, 一个尺寸合理的验证集可以让代码更简单, 不需要用几个数据集来交叉验证
# 你可能会听到人们说他们'交叉验证'一个参数, 但是大多数情况下, 他们实际是使用的一个验证集

# 超参数范围
# 在对数尺度上进行超参数搜索
# 例如, 一个典型的学习率应该看起来是这样: learning_rate = 10 ** uniform(-6, 1)
# 也就是说, 我们从标准分布中随机生成了一个数字, 然后让它成为10的阶数, 对于正则化强度, 可以采用同样的策略
# 直观地说, 这是因为学习率和正则化强度都对于训练的动态进程有乘的效果
# 例如: 当学习率是0.001的时候, 如果对其固定地增加0.01, 那么对于学习进程会有很大影响
# 然而当学习率是10的时候, 影响就微乎其微了, 这就是因为学习率乘以了计算出的梯度
# 因此, 比起加上或者减少某些值, 思考学习率的范围是乘以或者除以某些值更加自然
# 但是有一些参数(比如随机失活)还是在原始尺度上进行搜索(例如: dropout=uniform(0,1) )

# 随机搜索优于网格搜索
# 通常, 有些超参数比其余的更重要, 通过随机搜索, 而不是网格化的搜索, 可以让你更精确地发现那些比较重要的超参数的好数值

# 对于边界上的最优值要小心
# 这种情况一般发生在你在一个不好的范围内搜索超参数(比如学习率)的时候
# 比如, 假设我们使用 learning_rate = 10 ** uniform(-6,1)来进行搜索
# 一旦我们得到一个比较好的值, 一定要确认你的值不是出于这个范围的边界上, 不然你可能错过更好的其他搜索范围

# 从粗到细地分阶段搜索
# 在实践中, 先进行初略范围(比如10 ** [-6, 1])搜索, 然后根据好的结果出现的地方, 缩小范围进行搜索
# 进行粗搜索的时候, 让模型训练一个周期就可以了, 因为很多超参数的设定会让模型没法学习, 或者突然就爆出很大的损失值
# 第二个阶段就是对一个更小的范围进行搜索, 这时可以让模型运行5个周期, 而最后一个阶段就在最终的范围内进行仔细搜索, 运行很多次周期

# 贝叶斯超参数最优化
# 是一整个研究领域, 主要是研究在超参数空间中更高效的导航算法
# 其核心的思路是在不同超参数设置下查看算法性能时, 要在探索和使用中进行合理的权衡
# 基于这些模型, 发展出很多的库, 比较有名的有: Spearmint, SMAC, 和Hyperopt
# 然而, 在卷积神经网络的实际使用中, 比起上面介绍的先认真挑选的一个范围, 然后在该范围内随机搜索的方法，这个方法还是差一些

''' 模型集成 '''

# 在实践的时候, 有一个总是能提升神经网络几个百分点准确率的办法, 就是在训练的时候训练几个独立的模型, 然后在测试的时候平均它们预测结果
# 集成的模型数量增加, 算法的结果也单调提升(但提升效果越来越少), 还有模型之间的差异度越大, 提升效果可能越好, 进行集成有以下几种方法:

# 同一个模型，不同的初始化
# 使用交叉验证来得到最好的超参数, 然后用最好的参数来训练不同初始化条件的模型, 这种方法的风险在于多样性只来自于不同的初始化条件

# 在交叉验证中发现最好的模型
# 使用交叉验证来得到最好的超参数, 然后取其中最好的几个(比如10个)模型来进行集成
# 这样就提高了集成的多样性, 但风险在于可能会包含不够理想的模型, 在实际操作中, 这样操作起来比较简单, 在交叉验证后就不需要额外的训练了

# 个模型设置多个记录点
# 如果训练非常耗时, 那就在不同的训练时间对网络留下记录点(比如每个周期结束), 然后用它们来进行模型集成
# 很显然, 这样做多样性不足, 但是在实践中效果还是不错的, 这种方法的优势是代价比较小

# 在训练的时候跑参数的平均值
# 和上面一点相关的, 还有一个也能得到1-2个百分点的提升的小代价方法
# 这个方法就是在训练过程中如果损失值相较于前一次权重出现指数下降时, 就在内存中对网络的权重进行一个备份
# 这样你就对前几次循环中的网络状态进行了平均, 你会发现这个'平滑'过的版本的权重总是能得到更少的误差
# 直观的理解就是目标函数是一个碗状的, 你的网络在这个周围跳跃, 所以对它们平均一下, 就更可能跳到中心去

# 模型集成的一个劣势就是在测试数据的时候会花费更多时间, 最近Geoff Hinton在“Dark Knowledge”上的工作很有启发:
# 其思路是通过将集成似然估计纳入到修改的目标函数中, 从一个好的集成中抽出一个单独模型

''' 卷积神经网络 '''

# 卷积网络和常规网络相似:
# 网络依旧是一个可导的评分函数: 输入是原始的图像像素, 输出是不同类别的评分
# 最后的全连接层被称为'输出层', 在分类问题中, 它输出的值被看做是不同类别的评分值。
# 网络依旧有一个损失函数(比如SVM或Softmax), 各种技巧和要点依旧适用于卷积神经网络

# 那么有哪些地方变化了呢?
# 卷积神经网络的结构基于一个假设, 即输入数据是图像, 基于该假设向结构中添加了一些特有的性质
# 这些特有属性使得前向传播函数实现起来更高效, 并且大幅度降低了网络中参数的数量

# 常规网对大尺寸图像效果不尽人意
# 在CIFAR-10中, 图像的尺寸是32x32x3(宽高均为32像素, 3个颜色通道)
# 因此, 第一个隐层中, 每一个单独的全连接神经元就有32x32x3=3072个权重
# 这个数量看起来还可以接受, 但是很显然这个全连接的结构不适用于更大尺寸的图像
# 举例说来, 一个尺寸为200x200x3的图像, 会让神经元包含200x200x3=120,000个权重值
# 而网络中肯定不止一个神经元, 那么参数的量就会快速增加, 显而易见, 这种全连接方式效率低下, 大量的参数也很快会导致网络过拟合

# 神经元的三维排列(数据深度)
# 卷积神经网络针对输入全部是图像的情况, 将结构调整得更加合理, 获得了不小的优势
# 卷积网的各层中的神经元是3维排列的: 宽度, 高度和深度(深度指激活数据体的第三个维度, 而不是整个网络的深度, 整个网络的深度指网络的层数)
# 举个例子, CIFAR-10中的图像作为卷积网的输入, 该数据体的维度是32x32x3(宽度, 高度和深度)
# 我们将看到, 层中的神经元将只与前一层中的一小块区域连接, 而不是采取全连接方式
# 对于用来分类CIFAR-10中的图像的卷网, 其最后的输出层的维度是1x1x10
# 因为在卷积网结构的最后部分将会把全尺寸的图像压缩为包含分类评分的一个向量, 向量是在深度方向排列的

# 一个简单的卷积网由各种层按顺序排列组成, 网络中的每个层使用一个可以微分的函数将激活数据从一个层传递到另一个层
# 卷积网主要由三种类型的层构成: 卷积层, 汇聚(Pooling)层, 全连接层(全连接层和常规网中的一样)
# 通过将这些层叠加起来, 就可以构建一个完整的卷积神经网络

# 网络结构例子(概述)
# 一个用于CIFAR-10图像数据分类的卷积神经网络(VGG)的结构可以是[输入层-卷积层-ReLU层-汇聚层-全连接层]
# conv-relu-conv-relu-pool  -conv-relu-conv-relu-pool  -conv-relu-conv-relu-pool  -fc
# 输入层: 输入[32x32x3]存有图像的原始像素值, 本例中图像宽高均为32, 有3个颜色通道
# 卷积层: 神经元与输入层中的一个局部区域相连, 每个神经元都计算自己与输入层相连的小区域与自己权重的内积
#        卷积层会计算所有神经元的输出, 如果我们使用12个滤波器(也叫作核), 得到的输出数据体的维度就是[32x32x12]
# ReLU层: 将会逐个元素地进行激活函数操作, 比如使用以0为阈值的max(0, x)作为激活函数, 该层对数据尺寸没有改变, 还是[32x32x12]
# 汇聚层: 在空间维度(宽度和高度)上进行降采样(downsampling)操作, 数据尺寸变为[16x16x12]。
# 全连接层: 计算分类评分, 数据尺寸变为[1x1x10], 其中10个数字对应的就是CIFAR-10中10个类别的分类评分值
#          正如其名, 全连接层与常规神经网络一样, 其中每个神经元都与前一层中所有神经元相连接

''' 卷积层 '''

# 概述和直观介绍
# 卷积层的参数是由可学习的滤波器集合构成的, 每个滤波器在空间上(宽度和高度)都比较小, 但是深度和输入数据一致
# 举例来说, 卷积神经网络第一层的一个典型的滤波器的尺寸可以是5x5x3(宽高都是5像素, 深度是3是因为图像应为颜色通道, 所以有3的深度)
# 在前向传播的时候, 让每个滤波器都在输入数据的宽度和高度上滑动(更精确地说是卷积), 然后计算整个滤波器和输入数据任一处的内积
# 当滤波器沿着输入数据的宽度和高度滑过后, 会生成一个2维的激活图(activation map), 激活图给出了在每个空间位置处滤波器的反应
# 直观地来说, 网络会让滤波器学习到当它看到某些类型的视觉特征时就激活
# 具体的视觉特征可能是某些方位上的边界, 或者在第一层上某些颜色的斑点, 甚至可以是网络更高层上的蜂巢状或者车轮状图案

# 在每个卷积层上, 我们会有一整个集合的滤波器(比如12个), 每个都会生成一个不同的二维激活图
# 将这些激活映射在深度方向上层叠起来就生成了输出数据

# 以大脑做比喻
# 那么输出的3D数据中的每个数据项可以被看做是神经元的一个输出, 而该神经元只观察输入数据中的一小部分
# 并且和空间上左右两边的所有神经元共享参数(因为这些数字都是使用同一个滤波器得到的结果)

# 局部连接
# 在处理图像这样的高维度输入时, 让每个神经元都与前一层中的所有神经元进行全连接是不现实的
# 相反, 我们让每个神经元只与输入数据的一个局部区域连接, 该连接的空间大小叫做神经元的感受野(receptive field)
# 它的尺寸是一个超参数(其实就是滤波器的空间尺寸), 在深度方向上, 这个连接的大小总是和输入量的深度相等
# 需要再次强调的是, 我们对待空间维度(宽和高)与深度维度是不同的: 连接在空间(宽高)是局部的, 但是在深度上总是和输入数据的深度一致
# 例1: 假设输入数据体尺寸为[32x32x3](比如CIFAR-10的RGB图像), 如果感受野(或滤波器尺寸)是5x5
# 那么卷积层中的每个神经元会有输入数据体中[5x5x3]区域的权重, 共5x5x3=75个权重(还要加一个偏差参数)
# 注意这个连接在深度维度上的大小必须为3, 和输入数据体的深度一致
# 例2: 假设输入数据体的尺寸是[16x16x20], 感受野尺寸是3x3, 那么卷积层中每个神经元和输入数据体就有3x3x20=180个连接
# 再次提示: 在空间上连接是局部的(3x3), 但是在深度上是和输入数据体一致的(20)

# 空间排列
# 3个超参数控制着输出数据体的尺寸: 深度(depth), 步长(stride), 零填充(zero-padding)

# 深度(depth)
# 输出数据体的深度是一个超参数: 它和使用的滤波器的数量一致, 而每个滤波器在输入数据中寻找一些不同的东西
# 举例来说, 如果第一个卷积层的输入是原始图像, 那么在深度维度上的不同神经元将可能被不同方向的边界, 或者是颜色斑点激活
# 我们将这些沿着深度方向排列, 感受野相同的神经元集合称为深度列(depth column), 也有人使用纤维(fibre)来称呼它们

# 步长(stride)
# 在滑动滤波器的时候, 必须指定步长, 当步长为1, 滤波器每次移动1个像素, 当步长为2(或者不常用的3, 或者更多, 这些在实际中很少使用)
# 滤波器滑动时每次移动2个像素, 这个操作会让输出数据体在空间上变小

# 零填充(zero-padding)
# 有时候将输入数据体用0在边缘处进行填充是很方便的, 这个零填充(zero-padding)的尺寸是一个超参数
# 零填充有一个良好性质, 即可以控制输出数据体的空间尺寸(最常用的是用来保持输入数据体在空间上的尺寸, 这样输入和输出的宽高都相等)

# 输出数据体在空间上的尺寸可以通过输入数据体尺寸(W), 卷积层中神经元的感受野尺寸(F), 步长(S)和零填充的数量(P)的函数来计算
# (译者注: 这里假设输入数组的空间形状是正方形, 即高度和宽度相等)输出数据体的空间尺寸为(W-F +2P)/S+1
# 比如输入是7x7, 滤波器是3x3, 步长为1, 填充为0, 那么就能得到一个5x5的输出, 如果步长为2, 输出就是3x3

# 使用零填充:
# 一般说来, 当步长S=1时, 零填充的值是P=(F-1)/2, 这样就能保证输入和输出数据体有相同的空间尺寸
# 这样做非常常见, 在介绍卷积神经网络的结构的时候我们会详细讨论其原因

# 步长的限制:
# 注意这些空间排列的超参数之间是相互限制的
# 举例说来, 当输入尺寸 W = 10, 不使用零填充则 P = 0, 滤波器尺寸 F = 3, 这样步长 S = 2, 就行不通
# 因为 (W - F + 2P)/S + 1 = (10 - 3 + 0)/2 + 1 = 4.5, 结果不是整数, 这就是说神经元不能整齐对称地滑过输入数据体
# 因此, 这些超参数的设定就被认为是无效的, 一个卷积神经网络库可能会报出一个错误, 或者修改零填充值来让设置合理
# 或者修改输入数据体尺寸来让设置合理, 或者其他什么措施, 在后面的卷积神经网络结构小节中
# 可以看到合理地设置网络的尺寸让所有的维度都能正常工作, 这件事可是相当让人头痛的, 而使用零填充和遵守其他一些设计策略将会有效解决这个问题

# 真实案例:
# Krizhevsky构架赢得了2012年的ImageNet挑战, 其输入图像的尺寸是[227x227x3]
# 在第一个卷积层, 神经元使用的感受野尺寸 F = 11, 步长 S = 4, 不使用零填充 P = 0
# 因为(227-11)/4+1=55, 卷积层的深度 K = 96, 则卷积层的输出数据体尺寸为[55x55x96]
# 55x55x96个神经元中, 每个都和输入数据体中一个尺寸为[11x11x3]的区域全连接
# 在深度列上的96个神经元都是与输入数据体中同一个[11x11x3]区域连接, 但是权重不同
# 有一个有趣的细节, 在原论文中, 说的输入图像尺寸是224x224, 这是肯定错误的, 因为(224-11)/4+1的结果不是整数
# 这件事在卷积神经网络的历史上让很多人迷惑, 而这个错误到底是怎么发生的没人知道
# 我的猜测是Alex忘记在论文中指出自己使用了尺寸为3的额外的零填充

# 参数共享
# 在卷积层中使用参数共享是用来控制参数的数量
# 就用上面的例子, 在第一个卷积层就有55x55x96=290,400个神经元, 每个有11x11x3=364个参数和1个偏差
# 将这些合起来就是290400x364=105,705,600个参数, 单单第一层就有这么多参数, 显然这个数目是非常大的

# 作一个合理的假设:
# 如果一个特征在计算某个空间位置(x, y)的时候有用, 那么它在计算另一个不同位置(x2, y2)的时候也有用
# 基于这个假设, 可以显著地减少参数数量, 换言之, 就是将深度维度上一个单独的2维切片看做深度切片(depth slice)
# 比如一个数据体尺寸为[55x55x96]就有96个深度切片, 每个尺寸为[55x55], 在每个深度切片上的神经元都使用同样的权重和偏差
# 在这样的参数共享下, 例子中的第一个卷积层就只有96个不同的权重集了, 一个权重集对应一个深度切片, 共有96x11x11x3=34,848个不同的权重
# 或34,944个参数(+96个偏差), 在每个深度切片中的55x55个权重使用的都是同样的参数
# 在反向传播的时候, 都要计算每个神经元对它的权重的梯度, 但是需要把同一个深度切片上的所有神经元对权重的梯度累加, 这样就得到了对共享权重的梯度
# 这样, 每个切片只更新一个权重集

# 注意, 如果在一个深度切片中的所有权重都使用同一个权重向量
# 那么卷积层的前向传播在每个深度切片中可以看做是在计算神经元权重和输入数据体的卷积(这就是'卷积层'名字由来)
# 这也是为什么总是将这些权重集合称为滤波器(filter或卷积核kernel), 因为它们和输入进行了卷积

# Krizhevsky等学习到的滤波器例子
# 这96个滤波器的尺寸都是[11x11x3], 在一个深度切片中, 每个滤波器都被55x55个神经元共享
# 注意参数共享的假设是有道理的: 如果在图像某些地方探测到一个水平的边界是很重要的, 那么在其他一些地方也会同样是有用的
# 这是因为图像结构具有平移不变性, 所以在卷积层的输出数据体的55x55个不同位置中, 就没有必要重新学习去探测一个水平边界了

# 注意有时候参数共享假设可能没有意义, 特别是当卷积神经网络的输入图像是一些明确的中心结构时候
# 这时候我们就应该期望在图片的不同位置学习到完全不同的特征, 一个具体的例子就是输入图像是人脸, 人脸一般都处于图片中心
# 你可能期望不同的特征, 比如眼睛特征或者头发特征可能(也应该)会在图片的不同位置被学习
# 在这个例子中, 通常就放松参数共享的限制, 将层称为局部连接层(Locally-Connected Layer)
'''

Numpy例子: 为了让讨论更加的具体, 我们用代码来展示上述思路, 假设输入数据体是numpy数组 X,那么:

一个位于 (x, y) 的深度列(或纤维)将会是 X[x, y, :]
在深度为 d 处的深度切片, 或激活图应该是 X[:, :, d]

卷积层例子:
假设输入数据体 X 的尺寸 X.shape: (11, 11, 4), 不使用零填充(P = 0), 滤波器的尺寸是 F = 5, 步长 S = 2
那么输出数据体的空间尺寸就是(11-5)/2+1=4, 即输出数据体的宽度和高度都是4
那么在输出数据体中的激活映射(称其为 V)看起来就是下面这样(在这个例子中, 只有部分元素被计算):

V[0, 0, 0] = np.sum(X[  :5, :5, :] * W0) + b0
V[1, 0, 0] = np.sum(X[ 2:7, :5, :] * W0) + b0
V[2, 0, 0] = np.sum(X[ 4:9, :5, :] * W0) + b0
V[3, 0, 0] = np.sum(X[6:11, :5, :] * W0) + b0

在numpy中, * 操作是进行数组间的逐元素相乘, 权重向量W0是该神经元的权重, b0是其偏差
在这里, W0被假设尺寸是 W0.shape: (5, 5, 4), 因为滤波器的宽高是5, 输入数据量的深度是4
注意在每一个点, 计算点积的方式和之前的常规神经网络是一样的
同时, 计算内积的时候使用的是同一个权重和偏差(因为参数共享), 在宽度方向的数字每次上升2(因为步长为2)
要构建输出数据体中的第二张激活图, 代码应该是:

V[0, 0, 1] = np.sum(X[  :5,   :5, :] * W1) + b1
V[1, 0, 1] = np.sum(X[ 2:7,   :5, :] * W1) + b1
V[2, 0, 1] = np.sum(X[ 4:9,   :5, :] * W1) + b1
V[3, 0, 1] = np.sum(X[6:11,   :5, :] * W1) + b1
V[0, 1, 1] = np.sum(X[  :5,  2:7, :] * W1) + b1 (在y方向上)
V[2, 3, 1] = np.sum(X[ 4:9, 6:11, :] * W1) + b1 (或两个方向上同时)

我们访问的是 V 的深度维度上的第二层(即index1), 因为是在计算第二个激活图, 所以这次试用的参数集就是W1了
在上面的例子中, 为了简洁略去了卷积层对于输出数组V中其他部分的操作
还有, 要记得这些卷积操作通常后面接的是ReLU层, 对激活图中的每个元素做激活函数运算, 这里没有显示

'''
# 小结: 卷积层的性质:
# 输入数据体的尺寸为 W1 × H1 × D1
# 4个超参数:
# 滤波器的数量 K
# 滤波器的空间尺寸 F
# 步长 S
# 零填充数量 P
# 输出数据体的尺寸为 W2 × H2 × D2, 其中:
# W2 = (W1 - F + 2P)/S + 1
# H2 = (H1 - F + 2P)/S + 1 (宽度和高度的计算方法相同)
# D2 = K
# 由于参数共享, 每个滤波器包含 F⋅F⋅D1 个权重, 卷积层一共有  (F⋅F⋅D1)⋅K 个权重和 K 个偏置
# 在输出数据体中, 第 d 个深度切片(空间尺寸是 W2⋅H2), 用第 d 个滤波器和输入数据进行有效卷积运算的结果(使用步长 S), 最后在加上第 d 个偏差
# 对这些超参数, 常见的设置是 F = 3, S = 1, P = 1, 同时设置这些超参数也有一些约定俗成的惯例和经验

# 用矩阵乘法实现
# 卷积运算本质上就是在滤波器和输入数据的局部区域间做点积, 卷积层的常用实现方式就是利用这一点, 将卷积层的前向传播变成一个巨大的矩阵乘法:
# 1. 输入图像的局部区域被im2col操作拉伸为列
#    比如, 如果输入是[227x227x3], 要与尺寸为 11x11x3 的滤波器以步长为4进行卷积, 就取输入中的 [11x11x3] 数据块
#    然后将其拉伸为长度为 11x11x3=363 的列向量, 重复进行这一过程
#    因为步长为4, 所以输出的宽高为(227-11)/4+1=55, 所以得到im2col操作的输出矩阵 X_col 的尺寸是 [363x3025]
#    其中每列是拉伸的感受野, 共有55x55=3,025个, 注意因为感受野之间有重叠, 所以输入数据体中的数字在不同的列中可能有重复
# 2. 卷积层的权重也同样被拉伸成行, 举例, 如果有96个尺寸为 [11x11x3] 的滤波器, 就生成一个矩阵 W_row, 尺寸为 [96x363]
# 3. 现在卷积的结果和进行一个大矩阵乘 np.dot(W_row, X_col) 是等价的了, 能得到每个滤波器和每个感受野间的点积
#    在我们的例子中, 这个操作的输出是[96x3025], 给出了每个滤波器在每个位置的点积输出
# 4. 结果最后必须被重新变为合理的输出尺寸 [55x55x96]

# 这个方法的缺点就是占用内存太多, 因为在输入数据体中的某些值在X_col中被复制了多次
# 但是, 其优点是矩阵乘法有非常多的高效实现方式, 我们都可以使用(比如常用的BLAS API), 还有, 同样的im2col思路可以用在汇聚操作中

# 反向传播: 卷积操作的反向传播(同时对于数据和权重)还是一个卷积(但是是和空间上翻转的滤波器)

# 1x1卷积
# 一些论文中使用了1x1的卷积, 这个方法最早是在论文Network in Network中出现
# 人们刚开始看见这个1x1卷积的时候比较困惑, 尤其是那些具有信号处理专业背景的人, 因为信号是2维的, 所以1x1卷积就没有意义
# 但是, 在卷积神经网络中不是这样, 因为这里是对3个维度进行操作, 滤波器和输入数据体的深度是一样的
# 比如, 如果输入是[32x32x3], 那么1x1卷积就是在高效地进行3维点积(因为输入深度是3个通道)

# 扩张卷积
# 最近一个研究(Fisher Yu和Vladlen Koltun的论文)给卷积层引入了一个新的叫扩张(dilation)的超参数
# 到目前为止, 我们只讨论了卷积层滤波器是连续的情况, 但是, 让滤波器中元素之间有间隙也是可以的, 这就叫做扩张
# 举例, 在某个维度上滤波器w的尺寸是3, 那么计算输入x的方式是: w[0]*x[0] + w[1]*x[1] + w[2]*x[2], 此时扩张为0
# 如果扩张为1, 那么计算为: w[0]*x[0] + w[1]*x[2] + w[2]*x[4]
# 换句话说, 操作中存在1的间隙, 在某些设置中, 扩张卷积与正常卷积结合起来非常有用, 因为在很少的层数内更快地汇集输入图片的大尺度特征
# 比如, 如果上下重叠2个3x3的卷积层, 那么第二个卷积层的神经元的感受野是输入数据体中5x5的区域(可以成这些神经元的有效感受野是5x5)
# 如果我们对卷积进行扩张, 那么这个有效感受野就会迅速增长

''' 汇聚层 '''

# 通常, 在连续的卷积层之间会周期性地插入一个汇聚层
# 它的作用是逐渐降低数据体的空间尺寸, 这样的话就能减少网络中参数的数量, 使得计算资源耗费变少, 也能有效控制过拟合
# 汇聚层使用MAX操作, 对输入数据体的每一个深度切片独立进行操作, 改变它的空间尺寸
# 最常见的形式是汇聚层使用尺寸2x2的滤波器, 以步长为2来对每个深度切片进行降采样, 将其中75%的激活信息都丢掉
# 每个MAX操作是从4个数字中取最大值(也就是在深度切片中某个2x2的区域), 深度保持不变, 汇聚层的一些公式:
# 输入数据体尺寸 W1 × H1 × D1
# 有两个超参数:
# 空间大小 F
# 步长 S
# 输出数据体尺寸 W2 × H2 × D2，其中
# W2 = (W1 - F)/S + 1
# H2 = (H1 - F)/S + 1
# D2 = D1
# 因为对输入进行的是固定函数计算，所以没有引入参数
# 在汇聚层中很少使用零填充

# 在实践中, 最大汇聚层通常只有两种形式: 一种是 F=3, S=2, 也叫重叠汇聚(overlapping pooling)
# 另一个更常用的是 F=2, S=2, 对更大感受野进行汇聚需要的汇聚尺寸也更大, 而且往往对网络有破坏性

# 普通汇聚(General Pooling)
# 除了最大汇聚, 汇聚单元还可以使用其他的函数, 比如平均汇聚(average pooling)或L-2范式汇聚(L2-norm pooling)
# 平均汇聚历史上比较常用, 但是现在已经很少使用了, 因为实践证明, 最大汇聚的效果比平均汇聚要好

# 反向传播: max(x,y)函数的反向传播可以简单理解为将梯度只沿最大的数回传
# 因此, 在向前传播经过汇聚层的时候, 通常会把池中最大元素的索引记录下来(有时这个也叫作道岔 switches), 这样在反向传播的时候梯度的路由就很高效

# 不使用汇聚层
# 很多人不喜欢汇聚操作, 认为可以不使用它, 比如在Striving for Simplicity: The All Convolutional Net一文中
# 提出使用一种只有重复的卷积层组成的结构, 抛弃汇聚层, 通过在卷积层中使用更大的步长来降低数据体的尺寸
# 有发现认为, 在训练一个良好的生成模型时, 弃用汇聚层也是很重要的
# 比如变化自编码器(VAEs: variational autoencoders)和生成性对抗网络(GANs: generative adversarial networks)
# 现在看起来, 未来的卷积网络结构中, 无汇聚层的结构不太可能扮演重要的角色

''' 归一化层 '''
# 在卷积神经网络的结构中, 提出了很多不同类型的归一化层, 有时候是为了实现在生物大脑中观测到的抑制机制
# 但是这些层渐渐都不再流行, 因为实践证明它们的效果即使存在, 也是极其有限的

''' 全连接层 '''
# 把全连接层转化成卷积层
# 全连接层和卷积层之间唯一的不同就是卷积层中的神经元只与输入数据中的一个局部区域连接, 并且在卷积列中的神经元共享参数
# 然而在两类层中, 神经元都是计算点积, 所以它们的函数形式是一样的, 因此, 将此两者相互转化是可能的:

# 对于任一个卷积层, 都存在一个能实现和它一样的前向传播函数的全连接层
# 权重矩阵是一个巨大的矩阵, 除了某些特定块(这是因为有局部连接), 其余部分都是零, 而在其中大部分块中, 元素都是相等的(因为参数共享)

# 相反, 任何全连接层都可以被转化为卷积层
# 比如, 一个 K=4096 的全连接层, 输入数据体的尺寸是 7×7×512, 这个全连接层可以被等效地看做一个的卷积层
# 换句话说, 就是将滤波器的尺寸设置为和输入数据体的尺寸一致了, 因为只有一个单独的深度列覆盖并滑过输入数据体
# 所以输出将变成 1×1×4096, 这个结果就和使用初始的那个全连接层一样了

# 全连接层转化为卷积层
# 在两种变换中, 将全连接层转化为卷积层在实际运用中更加有用
# 假设一个卷积神经网络的输入是224x224x3的图像, 一系列的卷积层和汇聚层将图像数据变为尺寸为7x7x512的激活数据体
# (在AlexNet中就是这样, 通过使用5个汇聚层来对输入数据进行空间上的降采样, 每次尺寸下降一半, 所以最终空间尺寸为224/2/2/2/2/2=7)
# 从这里可以看到, AlexNet使用了两个尺寸为4096的全连接层, 最后一个有1000个神经元的全连接层用于计算分类评分
# 我们可以将这3个全连接层中的任意一个转化为卷积层:

# 针对第一个连接区域是[7x7x512]的全连接层, 令其滤波器尺寸为F=7, 这样输出数据体就为[1x1x4096]了
# 针对第二个全连接层, 令其滤波器尺寸为F=1, 这样输出数据体为[1x1x4096]
# 对最后一个全连接层也做类似的, 令其F=1, 最终输出为[1x1x1000]

# 实际操作中, 每次这样的变换都需要把全连接层的权重W重塑成卷积层的滤波器
# 那么这样的转化有什么作用呢? 它在下面的情况下可以更高效: 让卷积网络在一张更大的输入图片上滑动
# (译者注: 即把一张更大的图片的不同区域都分别带入到卷积网络, 得到每个区域的得分), 得到多个输出
# 这样的转化可以让我们在单个向前传播的过程中完成上述的操作

# 举个例子, 如果我们想让224x224尺寸的浮窗, 以步长为32在384x384的图片上滑动,把每个经停的位置都带入卷积网络, 最后得到6x6个位置的类别得分
# 上述的把全连接层转换成卷积层的做法会更简便, 如果224x224的输入图片经过卷积层和汇聚层之后得到了[7x7x512]的数组
# 那么, 384x384的大图片直接经过同样的卷积层和汇聚层之后会得到[12x12x512]的数组(因为途径5个汇聚层, 尺寸变为384/2/2/2/2/2 = 12)
# 然后再经过上面由3个全连接层转化得到的3个卷积层, 最终得到[6x6x1000]的输出(因为(12 - 7)/1 + 1 = 6)
# 这个结果正是浮窗在原图经停的6x6个位置的得分!（译者注: 这一段的翻译与原文不同, 经过了译者较多的修改, 使更容易理解)

# 面对384x384的图像, 让(含全连接层)的初始卷积神经网络以32像素的步长独立对图像中的224x224块进行多次评价
# 其效果和使用把全连接层变换为卷积层后的卷积神经网络进行一次前向传播是一样的

# 自然, 相较于使用被转化前的原始卷积神经网络对所有36个位置进行迭代计算
# 使用转化后的卷积神经网络进行一次前向传播计算要高效得多, 因为36次计算都在共享计算资源, 这一技巧在实践中经常使用, 一次来获得更好的结果
# 比如, 通常将一张图像尺寸变得更大, 然后使用变换后的卷积神经网络来对空间上很多不同位置进行评价得到分类评分, 然后在求这些分值的平均值

# 最后, 如果我们想用步长小于32的浮窗怎么办? 用多次的向前传播就可以解决
# 比如我们想用步长为16的浮窗, 那么先使用原图在转化后的卷积网络执行向前传播, 然后分别沿宽度, 沿高度, 最后同时沿宽度和高度
# 把原始图片分别平移16个像素, 然后把这些平移之后的图分别带入卷积网络(译者注: 这一段的翻译与原文不同, 经过了译者较多的修改, 使更容易理解)

''' 卷积神经网络的结构 '''

# 卷积神经网络通常是由三种层构成: 卷积层, 汇聚层(除非特别说明, 一般就是最大值汇聚), 全连接层(简称FC)
# ReLU激活函数也应该算是是一层, 它逐元素地进行激活函数操作, 在本节中将讨论在卷积神经网络中这些层通常是如何组合在一起的

# 层的排列规律
# 卷积神经网络最常见的形式就是将一些卷积层和ReLU层放在一起, 其后紧跟汇聚层, 然后重复如此直到图像在空间上被缩小到一个足够小的尺寸
# 在某个地方过渡成成全连接层也较为常见, 最后的全连接层得到输出, 比如分类评分等, 换句话说, 最常见的卷积神经网络结构如下:
# INPUT -> [[CONV -> RELU]*N -> POOL?]*M -> [FC -> RELU]*K -> FC
# 其中*指的是重复次数, POOL?指的是一个可选的汇聚层, 其中 N>=0, 通常 N<=3, M>=0, K>=0,通常 K<3, 例如, 下面是一些常见的网络结构规律
# INPUT -> FC, 实现一个线性分类器, 此处 N = M = K = 0
# INPUT -> CONV -> RELU -> FC
# INPUT -> [CONV -> RELU -> POOL]*2 -> FC -> RELU -> FC, 此处在每个汇聚层之间有一个卷积层
# INPUT -> [CONV -> RELU -> CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> FC
# 此处每个汇聚层前有两个卷积层, 这个思路适用于更大更深的网络
# 因为在执行具有破坏性的汇聚操作前, 多重的卷积层可以从输入数据中学习到更多的复杂特征

# 几个小滤波器卷积层的组合比一个大滤波器卷积层好
# 假设你一层一层地重叠了3个3x3的卷积层(层与层之间有非线性激活函数)
# 在这个排列下, 第一个卷积层中的每个神经元都对输入数据体有一个3x3的视野
# 第二个卷积层上的神经元对第一个卷积层有一个3x3的视野, 也就是对输入数据体有5x5的视野
# 同样, 在第三个卷积层上的神经元对第二个卷积层有3x3的视野, 也就是对输入数据体有7x7的视野
# 假设不采用这3个3x3的卷积层, 使用一个单独的有7x7的感受野的卷积层, 那么所有神经元的感受野也是7x7
# 但是就有一些缺点, 首先, 多个卷积层与非线性的激活层交替的结构, 比单一卷积层的结构更能提取出深层的更好的特征
# 其次, 假设所有的数据有个通道，那么单独的7x7卷积层将会包含个参数, 而3个3x3的卷积层的组合仅有个参数
# 直观说来, 最好选择带有小滤波器的卷积层组合, 而不是用一个带有大的滤波器的卷积层
# 前者可以表达出输入数据中更多个强力特征, 使用的参数也更少, 唯一的不足是, 在进行反向传播时, 中间的卷积层可能会导致占用更多的内存

# 层的尺寸设置规律

# 输入层(包含图像的)
# 应该能被2整除很多次, 常用数字包括32(比如CIFAR-10), 64, 96(比如STL-10)或224(比如ImageNet卷积神经网络), 384和512

# 卷积层
# 应该使用小尺寸滤波器(比如3x3或最多5x5), 使用步长 S=1,
# 还有一点非常重要, 就是对输入数据进行零填充, 这样卷积层就不会改变输入数据在空间维度上的尺寸
# 比如, 当 F=3, 那就使用来 P=1 保持输入尺寸, 当 F=5, P=2, 一般对于任意 F, 当 P=(F-1)/2的时候能保持输入尺寸
# 如果必须使用更大的滤波器尺寸(比如7x7之类), 通常只用在第一个面对原始图像的卷积层上

# 汇聚层
# 负责对输入数据的空间维度进行降采样, 最常用的设置是用用2x2感受野(即 F=2)的最大值汇聚, 步长为2(S=2)
# 注意这一操作将会把输入数据中75%的激活数据丢弃(因为对宽度和高度都进行了2的降采样), 另一个不那么常用的设置是使用3x3的感受野, 步长为2
# 最大值汇聚的感受野尺寸很少有超过3的, 因为汇聚操作过于激烈, 易造成数据信息丢失, 这通常会导致算法性能变差

# 减少尺寸设置的问题
# 上文中展示的两种设置是很好的, 因为所有的卷积层都能保持其输入数据的空间尺寸, 汇聚层只负责对数据体从空间维度进行降采样
# 如果使用的步长大于1并且不对卷积层的输入数据使用零填充, 那么就必须非常仔细地监督输入数据体通过整个卷积神经网络结构的过程
# 确认所有的步长和滤波器都尺寸互相吻合, 卷积神经网络的结构美妙对称地联系在一起

# 为什么在卷积层使用1的步长?
# 在实际应用中, 更小的步长效果更好, 步长为1可以让空间维度的降采样全部由汇聚层负责, 卷积层只负责对输入数据体的深度进行变换

# 为何使用零填充?
# 使用零填充除了前面提到的可以让卷积层的输出数据保持和输入数据在空间维度的不变, 还可以提高算法性能
# 如果卷积层值进行卷积而不进行零填充, 那么数据体的尺寸就会略微减小, 那么图像边缘的信息就会过快地损失掉

# 因为内存限制所做的妥协:
# 在某些案例(尤其是早期的卷积神经网络结构)中, 基于前面的各种规则, 内存的使用量迅速飙升
# 例如, 使用64个尺寸为3x3的滤波器对224x224x3的图像进行卷积, 零填充为1, 得到的激活数据体尺寸是[224x224x64]
# 这个数量就是一千万的激活数据, 或者就是72MB的内存(每张图就是这么多, 激活函数和梯度都是)
# 因为GPU通常因为内存导致性能瓶颈, 所以做出一些妥协是必须的, 在实践中, 人们倾向于在网络的第一个卷积层做出妥协
# 例如, 可能是在第一个卷积层使用步长为2, 尺寸为7x7的滤波器(比如在ZFnet中), 在AlexNet中, 滤波器的尺寸的11x11, 步长为4

# 计算上的考量
# 在构建卷积神经网络结构时, 最大的瓶颈是内存瓶颈, 大部分现代GPU的内存是3/4/6GB, 最好的GPU大约有12GB的内存, 要注意三种内存占用来源:

# 来自中间数据体尺寸
# 卷积神经网络中的每一层中都有激活数据体的原始数值, 以及损失函数对它们的梯度(和激活数据体尺寸一致)
# 通常, 大部分激活数据都是在网络中靠前的层中(比如第一个卷积层), 在训练时, 这些数据需要放在内存中, 因为反向传播的时候还会用到
# 但是在测试时可以聪明点: 让网络在测试运行时候每层都只存储当前的激活数据, 然后丢弃前面层的激活数据, 这样就能减少巨大的激活数据量

# 来自参数尺寸
# 即整个网络的参数的数量, 在反向传播时它们的梯度值, 以及使用momentum, Adagrad或RMSProp等方法进行最优化时的每一步计算缓存
# 因此, 存储参数向量的内存通常需要在参数向量的容量基础上乘以3或者更多

# 卷积神经网络实现还有各种零散的内存占用, 比如成批的训练数据, 扩充的数据等等

# 一旦对于所有这些数值的数量有了一个大略估计(包含激活数据, 梯度和各种杂项), 数量应该转化为以GB为计量单位
# 把这个值乘以4, 得到原始的字节数(因为每个浮点数占用4个字节, 如果是双精度浮点数那就是占用8个字节)
# 然后多次除以1024分别得到占用内存的KB, MB, 最后是GB计量
# 如果你的网络工作得不好, 一个常用的方法是降低批尺寸(batch size), 因为绝大多数的内存都是被激活数据消耗掉了
